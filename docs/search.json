{
  "articles": [
    {
      "path": "about.html",
      "title": "About",
      "author": [],
      "contents": "\r\nHi I am Siwei\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-17T11:01:17-06:00"
    },
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-17T11:01:20-06:00"
    },
    {
      "path": "final.html",
      "title": "Final Project",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\nI. About the Dataset (Describtion, source, and what purposes)\r\n\r\nDescribtion:\r\nSource:\r\nPurpose:\r\n\r\nII. Descriptive Stats: small discussion (NA, outliers, skewed)\r\n\r\n\r\n\r\nMissing Values\r\n\r\n\r\n# missing values\r\n# summary(BankChurners)\r\nBankChurners1 <- unknownToNA(BankChurners, unknown = c(\"Unknown\", \"\"))\r\n# summary(BankChurners1)\r\ntable(is.na(BankChurners1))\r\n\r\n\r\n\r\n FALSE   TRUE \r\n203003   9664 \r\n\r\n# sapply(BankChurners1, function(x) sum(is.na(x)))\r\nBankChurners2 <- knnImputation(BankChurners1)\r\n# summary(BankChurners2)\r\ntable(is.na(BankChurners2))\r\n\r\n\r\n\r\n FALSE \r\n212667 \r\n\r\nResampling\r\n\r\n\r\n# imbalanced dataset\r\ntable(BankChurners2$Attrition_Flag)\r\n\r\n\r\n\r\nExistingCustomer AttritedCustomer \r\n            8500             1627 \r\n\r\nBankChurners2_rose <- ROSE(Attrition_Flag ~., data = BankChurners2)$data\r\ntable(BankChurners2_rose$Attrition_Flag)\r\n\r\n\r\n\r\nExistingCustomer AttritedCustomer \r\n            5011             5116 \r\n\r\n# summary(BankChurners2_rose)\r\n# str(BankChurners2_rose)\r\n# View(BankChurners2_rose)\r\n# BankChurners2_rose %>% \r\n#   mutate_if(is.factor, ~ factor(trimws(., whitespace = \"\\\\s*-.*\")))\r\n\r\n\r\n\r\nIII. Describe the model\r\n\r\nGradient Boosting Tree:\r\nRandom Forest:\r\n\r\nIV. Describe the process and results\r\n\r\nProcess:\r\nResults:\r\n\r\nV. Code (summary, split data, run, results)\r\nshould I use PCA before RF bcz it takes forever to run RF\r\n\r\n\r\n# caret-PCA\r\n# BankChurners_pca <- BankChurners2_rose\r\n# # BankChurners_pca <- as.numeric(BankChurners2_rose)\r\n# BankChurners2_pca <- preProcess(BankChurners_pca, method = \"pca\", pcaComp = 12)\r\n# BankChurners2_pca\r\n# BankChurners2_pca_stat <- prcomp(BankChurners_pca[, -2])\r\n# plot(BankChurners2_pca_stat, type = \"l\")\r\n\r\n# FactoMineR-PCA\r\n# BankChurners2_rose_pca <- BankChurners2_rose\r\n# BankChurners_pca <- PCA(BankChurners2_rose_pca, \r\n#                         ncp = 5,\r\n#                         ind.sup = 2,\r\n#                         quali.sup = c(2, 4, 6, 7, 9))\r\n# pca_barplot <- barplot(BankChurners_pca$eig[, 1], \r\n#                        main = \"Eigenvalues\", \r\n#                        names.arg = 1:nrow(BankChurners_pca$eig))\r\n# summary(BankChurners_pca)\r\n# BankChurners_pca$eig\r\n# BankChurners_pca$var\r\n\r\n# FactoMineR-FAMD\r\n# BankChurners2_rose_pca <- BankChurners2_rose\r\n# BankChurners_pca <- FAMD(BankChurners2_rose_pca, \r\n#      ncp = 16,\r\n#      sup.var = 2,\r\n#      graph = FALSE)\r\n# BankChurners_pca$eig\r\n# pca_barplot <- barplot(BankChurners_pca$eig[, 1], \r\n#                        main = \"Eigenvalues\", \r\n#                        names.arg = 1:nrow(BankChurners_pca$eig))\r\n\r\n\r\n\r\nData Split\r\n\r\n\r\nindex <- createDataPartition(BankChurners2_rose$Attrition_Flag, p = .6, list = FALSE, times = 1)\r\ntrain <- BankChurners2_rose[index,]\r\ntest <- BankChurners2_rose[-index,]\r\n\r\n\r\n\r\nModel-Training\r\n\r\n\r\nchurn_RF <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 6\r\n)\r\n\r\n\r\n\r\nModel-Testing\r\n\r\n\r\nchurn_RF_pred <- predict(churn_RF, test, type = \"prob\")\r\nchurn_RF_test_pred <- cbind(churn_RF_pred, test)\r\nchurn_RF_test_pred <- churn_RF_test_pred %>% \r\n  mutate(prediction = if_else(ExistingCustomer > AttritedCustomer, \"ExistingCustomer\", \"AttritedCustomer\"))\r\ntable(churn_RF_test_pred$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n            2114             1936 \r\n\r\nPerformance\r\n\r\n\r\nconfusionMatrix(factor(churn_RF_test_pred$prediction), factor(churn_RF_test_pred$Attrition_Flag))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             1623              313\r\n  AttritedCustomer              381             1733\r\n                                          \r\n               Accuracy : 0.8286          \r\n                 95% CI : (0.8167, 0.8401)\r\n    No Information Rate : 0.5052          \r\n    P-Value [Acc > NIR] : < 2e-16         \r\n                                          \r\n                  Kappa : 0.6571          \r\n                                          \r\n Mcnemar's Test P-Value : 0.01098         \r\n                                          \r\n            Sensitivity : 0.8099          \r\n            Specificity : 0.8470          \r\n         Pos Pred Value : 0.8383          \r\n         Neg Pred Value : 0.8198          \r\n             Prevalence : 0.4948          \r\n         Detection Rate : 0.4007          \r\n   Detection Prevalence : 0.4780          \r\n      Balanced Accuracy : 0.8284          \r\n                                          \r\n       'Positive' Class : ExistingCustomer\r\n                                          \r\n\r\nvar_import <- varImp(churn_RF)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(var_import)\r\n\r\n\r\n\r\nOverall\r\nTotal_Trans_Ct\r\n100.0000000\r\nTotal_Ct_Chng_Q4_Q1\r\n52.3440562\r\nTotal_Trans_Amt\r\n37.0456672\r\nTotal_Relationship_Count\r\n32.3691455\r\nMonths_Inactive_12_mon\r\n29.7206153\r\nTotal_Amt_Chng_Q4_Q1\r\n25.1475232\r\nContacts_Count_12_mon\r\n23.7543125\r\nTotal_Revolving_Bal\r\n16.0882548\r\nCustomer_Age\r\n15.9575731\r\nMonths_on_book\r\n15.6122966\r\nAvg_Open_To_Buy\r\n14.2400466\r\nIncome_Level\r\n13.9393870\r\nCredit_Limit\r\n13.7861466\r\nAvg_Utilization_Ratio\r\n13.7561393\r\nDependent_count\r\n13.5437120\r\nCLIENTNUM\r\n13.5401712\r\nGenderF\r\n3.7121192\r\nMarital_StatusSingle\r\n2.3351003\r\nEducation_LevelGraduate\r\n1.6852358\r\nEducation_LevelHigh School\r\n1.3652059\r\nCard_CategoryBlue\r\n1.3524077\r\nEducation_LevelCollege\r\n1.2210126\r\nEducation_LevelPost-Graduate\r\n1.1829780\r\nEducation_LevelDoctorate\r\n0.8623315\r\nMarital_StatusDivorced\r\n0.6848503\r\nCard_CategorySilver\r\n0.6653834\r\nCard_CategoryPlatinum\r\n0.0000000\r\n\r\nVI. Results\r\n\r\nResults:\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-17T14:24:15-06:00"
    },
    {
      "path": "index.html",
      "title": "Siwei Jiang",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Siwei Jiang\r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          Resume\r\n          \r\n          \r\n          Project\r\n           \r\n          ▾\r\n          \r\n          \r\n          Rsquared\r\n          Machine Learning\r\n          Final Project\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            Siwei Jiang\r\n          \r\n          \r\n            \r\n              Change me later:)\r\n              \r\n              \r\n              h1, body {\r\n                color: #bdaeea;\r\n              }\r\n              \r\n            \r\n              Change me later:)\r\n              \r\n              \r\n              h1, body {\r\n                color: #bdaeea;\r\n              }\r\n              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                      Github\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Blog\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                    Github\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Email\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Blog\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2021-11-17T11:04:02-06:00"
    },
    {
      "path": "ml.html",
      "title": "ML",
      "author": [],
      "contents": "\r\nuse hw\r\ndescribe the model\r\ndescribe the process and results\r\ncode\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-17T11:04:04-06:00"
    },
    {
      "path": "resume.html",
      "title": "Résumé",
      "author": [],
      "contents": "\r\n\r\n\r\na {n  \r\n  text-decoration: none; \r\n  color: rgba(121, 205, 205);\r\n}\r\na:hover {\r\n  color: rgba(255, 182, 255, 0.8);\r\n}\r\nul {\r\n  list-style: none; /* Remove list bullets bcz don't know how to change color */\r\n  padding: 0;\r\n  margin: 0;\r\n}\r\nli::before {\r\n  content: \"•\"; \r\n  color: \"#5A59A3\";\r\n}\r\nh1 {\r\n  font-family: candara; /* title */\r\n  font-style: italic;\r\n}\r\nh2 {\r\n  font-family: candara;\r\n  font-style: italic;\r\n  color: rgba(134, 35, 141, 0.72);\r\n}\r\np code,\r\nli code {\r\n    line-height: 2.0; \r\n    white-space: nowrap;\r\n}\r\nbody {\r\n    width: 100vw;\r\n    height: 100vh;\r\n    margin: 0;\r\n    background: linear-gradient(\r\n        130deg, \r\n        #5A59A3, \r\n        #C66060\r\n    ) no-repeat  fixed;\r\n}\r\n\r\nEducation\r\nBachelor of Business in Accounting: Adkerson School of Accountancy May 2020\r\nMinor in Business Analytics\r\nMississippi State University, Mississippi State, MS\r\nWorking Experience\r\n  Private Accountant for a Fire Protection Service CompanyFall 2014 – Fall 2015\r\n  Hunan, China\r\n              Journal entries and general ledger preparation\r\n              Bank statements and reconciliation\r\n              Examining expenses submitted by the construction manager\r\n              Taxation preparation during tax season\r\nCourse Group Projects\r\n  PowerPoint and social platforms: Marketing strategy plans for a drone startup\r\n  Excel and Word: Prepared consolidated financial reports for company acquisition\r\n  R: Bankruptcy analysis. Methods: holdout validation in discriminant analysis and logistic         regression analysis, and cross-validation in decision tree analysis\r\nComputer Skills\r\n  Advanced in Microsoft Office including Excel, Word, and PowerPoint\r\n  Developing knowledge in Access, R, SAS, and Tableau\r\nVolunteer Work\r\n  West Point Clay County Animal Shelter\r\n  MSU Community Garden\r\n  Starkville Community Farmers Market\r\n  The Salvation Army\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-17T11:04:05-06:00"
    },
    {
      "path": "rsquared.html",
      "title": "R-squared",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\nTime to blow RSquared up1 💥\r\nR-squared is a statistic that often accompanies regression output. It ranges in value from 0 to 1 and is usually interpreted as summarizing the percent of variation in the response that the regression model explains. So an R-squared of 0.65 might mean that the model explains about 65% of the variation in our dependent variable. Given this logic, we prefer our regression models have a high R-squared.\r\nIn R, we typically get R-squared by calling the summary function on a model object. Here’s a quick example using simulated data:\r\n\r\n\r\n# independent variable\r\nx <- 1:20 \r\n# for reproducibility\r\nset.seed(1) \r\n# dependent variable; function of x with random error\r\ny <- 2 + 0.5*x + rnorm(20,0,3) \r\n# simple linear regression\r\nmod <- lm(y~x)\r\n# request just the r-squared value\r\nsummary(mod)$r.squared          \r\n\r\n\r\n[1] 0.6026682\r\n\r\nOne way to express R-squared is as the sum of squared fitted-value deviations divided by the sum of squared original-value deviations:\r\n\\[\r\nR^{2} =  \\frac{\\sum (\\hat{y} – \\bar{\\hat{y}})^{2}}{\\sum (y – \\bar{y})^{2}}\r\n\\]\r\nWe can calculate it directly using our model object like so:\r\n\r\n\r\n# extract fitted (or predicted) values from model\r\nf <- mod$fitted.values\r\n# sum of squared fitted-value deviations\r\nmss <- sum((f - mean(f))^2)\r\n# sum of squared original-value deviations\r\ntss <- sum((y - mean(y))^2)\r\n# r-squared\r\nmss/tss                      \r\n\r\n\r\n[1] 0.6026682\r\n\r\n1. R-squared does not measure goodness of fit. It can be arbitrarily low when the model is completely correct. By making\\(σ^2\\) large, we drive R-squared towards 0, even when every assumption of the simple linear regression model is correct in every particular.\r\nWhat is \\(σ^2\\)? When we perform linear regression, we assume our model almost predicts our dependent variable. The difference between “almost” and “exact” is assumed to be a draw from a Normal distribution with mean 0 and some variance we call \\(σ^2\\).\r\nThis statement is easy enough to demonstrate. The way we do it here is to create a function that (1) generates data meeting the assumptions of simple linear regression (independent observations, normally distributed errors with constant variance), (2) fits a simple linear model to the data, and (3) reports the R-squared. Notice the only parameter for sake of simplicity is sigma. We then “apply” this function to a series of increasing \\(σ\\) values and plot the results.\r\n\r\n\r\nr2.0 <- function(sig){\r\n  # our predictor\r\n  x <- seq(1,10,length.out = 100)   \r\n  # our response; a function of x plus some random noise\r\n  y <- 2 + 1.2*x + rnorm(100,0,sd = sig) \r\n  # print the R-squared value\r\n  summary(lm(y ~ x))$r.squared          \r\n}\r\nsigmas <- seq(0.5,20,length.out = 20)\r\n # apply our function to a series of sigma values\r\nrout <- sapply(sigmas, r2.0)            \r\nplot(rout ~ sigmas, type=\"b\")\r\n\r\n\r\n\r\n\r\nR-squared tanks hard with increasing sigma, even though the model is completely correct in every respect.\r\nR-squared can be arbitrarily close to 1 when the model is totally wrong.\r\nThe point being made is that R-squared does not measure goodness of fit.\r\n\r\n\r\nset.seed(1)\r\n# our predictor is data from an exponential distribution\r\nx <- rexp(50,rate=0.005)\r\n# non-linear data generation\r\ny <- (x-1)^2 * runif(50, min=0.8, max=1.2) \r\n# clearly non-linear\r\nplot(x,y)             \r\n\r\n\r\n\r\n\r\n\r\n\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.8485146\r\n\r\nIt’s very high at about 0.85, but the model is completely wrong. Using R-squared to justify the “goodness” of our model in this instance would be a mistake. Hopefully one would plot the data first and recognize that a simple linear regression in this case would be inappropriate.\r\n3. R-squared says nothing about prediction error, even with \\(σ^2\\) exactly the same, and no change in the coefficients. R-squared can be anywhere between 0 and 1 just by changing the range of X. We’re better off using Mean Square Error (MSE) as a measure of prediction error.\r\nMSE is basically the fitted y values minus the observed y values, squared, then summed, and then divided by the number of observations.\r\nLet’s demonstrate this statement by first generating data that meets all simple linear regression assumptions and then regressing y on x to assess both R-squared and MSE.\r\n\r\n\r\nx <- seq(1,10,length.out = 100)\r\nset.seed(1)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 0.9)\r\nmod1 <- lm(y ~ x)\r\nsummary(mod1)$r.squared\r\n\r\n\r\n[1] 0.9383379\r\n\r\n# Mean squared error\r\nsum((fitted(mod1) - y)^2)/100\r\n\r\n\r\n[1] 0.6468052\r\n\r\nNow repeat the above code, but this time with a different range of x. Leave everything else the same:\r\n\r\n\r\n # new range of x\r\nx <- seq(1,2,length.out = 100)      \r\nset.seed(1)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 0.9)\r\nmod1 <- lm(y ~ x)\r\nsummary(mod1)$r.squared\r\n\r\n\r\n[1] 0.1502448\r\n\r\n# Mean squared error\r\nsum((fitted(mod1) - y)^2)/100        \r\n\r\n\r\n[1] 0.6468052\r\n\r\nThe R-squared falls from 0.94 to 0.15 but the MSE remains the same. In other words the predictive ability is the same for both data sets, but the R-squared would lead you to believe the first example somehow had a model with more predictive power.\r\nR-squared can easily go down when the model assumptions are better fulfilled.\r\nLet’s examine this by generating data that would benefit from transformation. Notice the R code below is very much like our previous efforts but now we exponentiate our y variable.\r\n\r\n\r\nx <- seq(1,2,length.out = 100)\r\nset.seed(1)\r\ny <- exp(-2 - 0.09*x + rnorm(100,0,sd = 2.5))\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.003281718\r\n\r\nplot(lm(y ~ x), which=3)\r\n\r\n\r\n\r\n\r\nR-squared is very low and our residuals vs. fitted plot reveals outliers and non-constant variance. A common fix for this is to log transform the data. Let’s try that and see what happens:\r\n\r\n\r\nplot(lm(log(y)~x),which = 3) \r\n\r\n\r\n\r\n\r\nThe diagnostic plot looks much better. Our assumption of constant variance appears to be met. But look at the R-squared:\r\n\r\n\r\nsummary(lm(log(y)~x))$r.squared \r\n\r\n\r\n[1] 0.0006921086\r\n\r\nIt’s even lower! This is an extreme case and it doesn’t always happen like this. In fact, a log transformation will usually produce an increase in R-squared. But as just demonstrated, assumptions that are better fulfilled don’t always lead to higher R-squared.\r\nIt is very common to say that R-squared is “the fraction of variance explained” by the regression. \\[Yet\\] if we regressed X on Y, we’d get exactly the same R-squared. This in itself should be enough to show that a high R-squared says nothing about explaining one variable by another.\r\nThis is the easiest statement to demonstrate:\r\n\r\n\r\nx <- seq(1,10,length.out = 100)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 2)\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.737738\r\n\r\nsummary(lm(x ~ y))$r.squared\r\n\r\n\r\n[1] 0.737738\r\n\r\nDoes x explain y, or does y explain x? Are we saying “explain” to dance around the word “cause”? In a simple scenario with two variables such as this, R-squared is simply the square of the correlation between x and y:\r\n\r\n\r\nall.equal(cor(x,y)^2, summary(lm(x ~ y))$r.squared, summary(lm(y ~ x))$r.squared)\r\n\r\n\r\n[1] TRUE\r\n\r\nLet’s recap:\r\nR-squared does not measure goodness of fit.\r\nR-squared does not measure predictive error.\r\nR-squared does not necessarily increase when assumptions are better satisfied.\r\nR-squared does not measure how one variable explains another.\r\n\r\nhttps://data.library.virginia.edu/is-r-squared-useless/↩︎\r\n",
      "last_modified": "2021-11-17T11:04:12-06:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
