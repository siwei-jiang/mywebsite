{
  "articles": [
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-27T09:47:55-06:00"
    },
    {
      "path": "final_project.html",
      "title": "Final Project",
      "description": "This report is the final project for my accounitng analysis class, and the codes are borrowed from my professor, Dr. Hunt's [course website](https://professor-hunt.github.io/ACC8143/){target=\"_blank\"}.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nI. About the Dataset\r\nII. Descriptive Stats\r\nIII. The Models\r\nIV. The Process\r\nV. Code\r\ni. 🎄Random Forest Total NA⭐\r\nii. 🌴Random Forest NA & Var🍃\r\niii. 🔔Random Forest Train NA✨\r\niv. ⛄Random Forest Total NA & SMOTE❄️\r\nv. 🧦🎁Gradient Boosting Tree Total NA🎅🍪🥛\r\nvi. 🔔Gradient Boosting Tree Train NA✨\r\nvii. 🦌Gradient Boosting Tree Total NA & SMOTE🥕\r\nviii. 🌜Neural Network🕊️\r\n\r\nVI. Result\r\n\r\nI. About the Dataset\r\nI obtained this dataset from Kaggle1, and Sakshi Goyal uploaded it a year ago (2020). This dataset is about a 🏦bank’s customer churn issue. The manager💼 of the bank is interested in predicting which customer will leave this bank💸. By doing so, the bank can target those customers with special products and services to increase their satisfaction and customer retention🌞.\r\nIt contains 10,127 observations and 23 variables. Because I had some issues with Income Category values, so I add another column that used a scale of 1 through 5 to represent each income category. My data analyses are based on 20 variables, which excluded the Client Number and two Naive Bayes Classifiers😶.\r\nThe purpose of this project is to predict churned customers, so recall is an important model fit measurement📐. I also include accuracy and kappa as measurements of model fitness. I choose kappa because customer churn is only around 16% of total customers. Although some studies state kappa is not a good measure for classification model2, I think it is good enough for this project😎 I include a comparison table📊 in the Result section for each models’ performance.\r\nII. Descriptive Stats\r\nThis dataset has 9,664 missing values, which is 4.77% of the 202,540 total values. Most of those missing values are belong to categorical variables.\r\nAfter using kNN to replace all the missing data by calculating their nearest 10 neighbors 🏠🏡 values, the new dataset contains 0️⃣ missing values. The distribution of the target variable is not balanced⚖️, as attrited customers only represent 16% of the total customers.\r\n\r\n\r\nShow code\r\n\r\nBankChurners1 <- unknownToNA(BankChurners, unknown = c(\"\", \"Unknown\"))\r\n# summary(BankChurners1)\r\nNA_cnt <- table(is.na(BankChurners1))\r\nNA_pct <- prop.table(NA_cnt)\r\ncbind(NA_cnt, NA_pct)\r\n\r\n\r\n      NA_cnt     NA_pct\r\nFALSE 192876 0.95228597\r\nTRUE    9664 0.04771403\r\n\r\nShow code\r\n\r\n# replace all missing values \r\nBankChurners2 <- VIM::kNN(BankChurners1, \r\n                     variable = c(\"Dependent_count\", \"Education_Level\", \r\n                                  \"Marital_Status\", \"Income_Level\", \r\n                                  \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\",\r\n                                  \"Total_Revolving_Bal\", \"Total_Amt_Chng_Q4_Q1\",\r\n                                  \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\"),\r\n                     k = 10)\r\nBankChurners2 <- BankChurners2[,-c(21:30)]\r\ntable(is.na(BankChurners2))\r\n\r\n\r\n\r\n FALSE \r\n202540 \r\n\r\nShow code\r\n\r\ncounts <- table(BankChurners2$Attrition_Flag)\r\nproportions <- prop.table(counts)\r\ncbind(counts, proportions)\r\n\r\n\r\n                 counts proportions\r\nExistingCustomer   8500   0.8393404\r\nAttritedCustomer   1627   0.1606596\r\n\r\n\r\n\r\nTransaction Count Attrited customer has less variability and less spread regarding the total number of transactions. We can see that 50% of customer churn has less than 50 transaction counts and no of those customers have more than 100 transactions.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1, \r\n       mapping = aes(x = Attrition_Flag, \r\n                     y = Total_Trans_Ct,\r\n                     fill = Attrition_Flag)) +\r\n  labs(title = \"Boxplot: Total Transaction Count\",\r\n       tag = \"Fig. 1\") +\r\n  geom_boxplot(alpha = .3) +\r\n  theme(legend.position = \"none\") +\r\n  scale_fill_brewer(palette = \"Dark2\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nTransaction Amt💵 Both existing and attrited Customers are right-skewed due to outliers regarding their total transaction amounts.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1, \r\n       mapping = aes(x = Attrition_Flag, \r\n                     y = Total_Trans_Amt,\r\n                     fill = Attrition_Flag)) +\r\n  labs(title = \"Boxplot: Total Transaction Amount\",\r\n       tag = \"Fig. 2\") +\r\n  geom_boxplot(alpha = .3) +\r\n  theme(legend.position = \"none\") +\r\n  scale_fill_brewer(palette = \"Accent\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n🌠Credit Limit The majority of attrited customers have lower than $5000 credit.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1,\r\n       mapping = aes(x = Credit_Limit,\r\n                     fill = Attrition_Flag)) +\r\n  geom_histogram(color = \"#e9ecef\", \r\n                 alpha = 1,\r\n                 position = \"stack\") +\r\n  scale_fill_manual(values=c(\"#adb8ff\", \"#e8b5ff\")) +\r\n  theme_ipsum() +\r\n  labs(title = \"Histogram: Credit Limit vs Attrition\",\r\n       tag = \"Fig. 4\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nIncome vs Gender Females’ income levels are concentrated at low levels such as levels 1 and 2 while males have much higher income level distributions.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1,\r\n       mapping = aes(x = Income_Level,\r\n                     group = Gender,\r\n                     fill = Gender)) +\r\n  geom_density(adjust = 1.5, alpha = .4) +\r\n  theme_ipsum() +\r\n  labs(title = \"Density Plot: Gender vs Income Level\",\r\n       tag = \"Fig. 3\") +\r\n  scale_color_manual(values=c(\"M\"=\"blue\", \"F\"=\"pink\")) # not working\r\n\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nkable(IncomeLevel)\r\n\r\n\r\n\r\nIncome_Level\r\n\r\n\r\nIncome_Category\r\n\r\n\r\n1\r\n\r\n\r\nLess than $40K\r\n\r\n\r\n2\r\n\r\n\r\n$40K - $60K\r\n\r\n\r\n3\r\n\r\n\r\n$60K - $80K\r\n\r\n\r\n4\r\n\r\n\r\n$80K - $120K\r\n\r\n\r\n5\r\n\r\n\r\n$120K +\r\n\r\n\r\n\r\n\r\nIII. The Models\r\nRandom Forest🌳: Decision trees are sensitive to changes, introducing randomness to each split of trees, reduces the over-fitting issue. Also, random forest uses bagging method to make decisions based on a majority vote from each individual tree.\r\nGradient Boosting Tree🌲: Gradient boosting is normally better💪 than random forest due to its arbitrary cost functions for classification purpose3.\r\nNeural Network🔮: Neural network is very effective and efficient in making inferences and detecting patterns from complex datasets. It uses the input information to optimize the weight of those inputs and then generates outputs. It also minimizes the errors ❌ of those outputs to improve those processed inputs until the errors become small enough🔄. The final result is based on minimized errors❓\r\nIV. The Process\r\nI split the dataset into the training set and testing set based on 4 different ratios, and 7:3 ratio has the best result, so I use this ratio for rest of models: 🌳random forest, gradient boosting tree🌲, and 💫neural network🔮 to train🚋 each dataset. After importing the original dataset, I use the kNN function with k = 10 to replace those missing values. For comparison, I replace missing values only in the training set and leave the testing set as it is. Both random forest and gradient boosting trees have better performance in terms of recall after re-sampling in the training sets. Nerual network model turns out to has the worst performance.\r\nV. Code\r\ni. 🎄Random Forest Total NA⭐\r\n\r\nOriginal Dataset with Total Missing Value Replaced\r\n\r\nI use 4 different ratio to split the dataset into a training set and a testing set. The 7:3 ratio has the best performance. The model has 0.9661 of accuracy🎯 and 0.8683 in kappa, this huge drop probably is due to the imbalanced distribution of the attrition. The recall is 0.8381, which means that this model will misclassify 2 attrited customers of every 10 customers as existing customers.\r\n\r\n\r\nShow code\r\n\r\ncomparison <- matrix(c(0.9599, 0.8437, 0.8155, 0.9590, 0.8406, 0.8154, 0.9661, 0.8683, 0.8381, 0.9580, 0.8359, 0.8062),\r\n                    ncol = 3, byrow = TRUE)\r\ncolnames(comparison) <- c(\"Accuracy\", \"Kappa\", \"Recall\")\r\nrownames(comparison) <- c(\"5:5\", \"6:4\", \"7:3\", \"8:2\")\r\ncomparison <- as.data.frame.matrix(comparison) \r\nkable(comparison) %>% \r\n  row_spec(3, color = \"white\", background = \"#bdaeea\")\r\n\r\n\r\n\r\n\r\n\r\nAccuracy\r\n\r\n\r\nKappa\r\n\r\n\r\nRecall\r\n\r\n\r\n5:5\r\n\r\n\r\n0.9599\r\n\r\n\r\n0.8437\r\n\r\n\r\n0.8155\r\n\r\n\r\n6:4\r\n\r\n\r\n0.9590\r\n\r\n\r\n0.8406\r\n\r\n\r\n0.8154\r\n\r\n\r\n7:3\r\n\r\n\r\n0.9661\r\n\r\n\r\n0.8683\r\n\r\n\r\n0.8381\r\n\r\n\r\n8:2\r\n\r\n\r\n0.9580\r\n\r\n\r\n0.8359\r\n\r\n\r\n0.8062\r\n\r\n\r\n\r\n\r\n5:5 Data split in 5:5 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .5, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF1\r\n\r\n# feature importance\r\nvar_imp1 <- varImp(churn_RF1)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp1)) \r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n100.00000\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n92.28458\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n54.31663\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n45.33162\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n30.42752\r\n\r\n\r\nCustomer_Age\r\n\r\n\r\n18.22175\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp1, aes(x = reorder(rownames(var_imp1), Overall), y = Overall)) +\r\n  geom_point(color = \"plum1\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp1), xend = rownames(var_imp1), \r\n                   y = 0, yend = Overall), color = \"skyblue\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +  \r\n  coord_flip()\r\n\r\n\r\n\r\nShow code\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred1$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             716             4347 \r\n\r\nShow code\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             4197              150\r\n  AttritedCustomer               53              663\r\n                                          \r\n               Accuracy : 0.9599          \r\n                 95% CI : (0.9541, 0.9651)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8437          \r\n                                          \r\n Mcnemar's Test P-Value : 1.607e-11       \r\n                                          \r\n            Sensitivity : 0.8155          \r\n            Specificity : 0.9875          \r\n         Pos Pred Value : 0.9260          \r\n         Neg Pred Value : 0.9655          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1310          \r\n   Detection Prevalence : 0.1414          \r\n      Balanced Accuracy : 0.9015          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\n# Accuracy : 0.9632  Kappa : 0.8586 Sensitivity : 0.8431\r\n\r\nggplot(as.data.frame(churn_matrix1$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"darkgreen\", \r\n                       na.value = \"gray\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Merry Christmas\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n6:4 Data split in 6:4 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .6, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF1\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             3354              120\r\n  AttritedCustomer               46              530\r\n                                          \r\n               Accuracy : 0.959           \r\n                 95% CI : (0.9524, 0.9649)\r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8406          \r\n                                          \r\n Mcnemar's Test P-Value : 1.463e-08       \r\n                                          \r\n            Sensitivity : 0.8154          \r\n            Specificity : 0.9865          \r\n         Pos Pred Value : 0.9201          \r\n         Neg Pred Value : 0.9655          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1309          \r\n   Detection Prevalence : 0.1422          \r\n      Balanced Accuracy : 0.9009          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\n# Accuracy : 0.9632  Kappa : 0.8586 Sensitivity : 0.8431\r\n\r\n\r\n\r\n\r\n\r\n7:3 Data split in 7:3 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF1\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred1$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             433             2605 \r\n\r\nShow code\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2526               79\r\n  AttritedCustomer               24              409\r\n                                          \r\n               Accuracy : 0.9661          \r\n                 95% CI : (0.959, 0.9722) \r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8683          \r\n                                          \r\n Mcnemar's Test P-Value : 1.033e-07       \r\n                                          \r\n            Sensitivity : 0.8381          \r\n            Specificity : 0.9906          \r\n         Pos Pred Value : 0.9446          \r\n         Neg Pred Value : 0.9697          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1346          \r\n   Detection Prevalence : 0.1425          \r\n      Balanced Accuracy : 0.9144          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\n\r\n\r\n8:2 Data split in 8:2 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .8, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             1678               63\r\n  AttritedCustomer               22              262\r\n                                          \r\n               Accuracy : 0.958           \r\n                 95% CI : (0.9484, 0.9663)\r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8359          \r\n                                          \r\n Mcnemar's Test P-Value : 1.434e-05       \r\n                                          \r\n            Sensitivity : 0.8062          \r\n            Specificity : 0.9871          \r\n         Pos Pred Value : 0.9225          \r\n         Neg Pred Value : 0.9638          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1294          \r\n   Detection Prevalence : 0.1402          \r\n      Balanced Accuracy : 0.8966          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\n\r\n\r\nii. 🌴Random Forest NA & Var🍃\r\n\r\nDataset with 14 variables and Total Missing Value Replaced\r\n\r\nEducation level🎓, marital status💑, card category💳, income level💰, dependent count👶, and gender👦 👩 are the least important variables that used for the final prediction. After dropping those 6 variables, the model performance decreased a little bit compared to the previous model’s.\r\n\r\n\r\nShow code\r\n\r\n# data split drop 6 var\r\nBankChurners_drop_var <- BankChurners2[-c(3:8)]\r\nindex_var <- createDataPartition(BankChurners_drop_var$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain_var <- BankChurners_drop_var[index,]\r\ntest_var <- BankChurners_drop_var[-index,]\r\n\r\n# train drop 6 var\r\nchurn_RF_var <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train_var,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF_var\r\n\r\n# test drop 6 var\r\nchurn_RF_pred_var <- predict(churn_RF_var, test_var, type = \"prob\")\r\nchurn_RF_test_pred_var <- cbind(churn_RF_pred_var, test_var)\r\nchurn_RF_test_pred_var <- churn_RF_test_pred_var %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred_var$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             299             1726 \r\n\r\nShow code\r\n\r\n# result drop 6 var\r\nchurn_matrix_var <- confusionMatrix(factor(churn_RF_test_pred_var$prediction), \r\n                                 factor(churn_RF_test_pred_var$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix_var\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             1671               55\r\n  AttritedCustomer               29              270\r\n                                          \r\n               Accuracy : 0.9585          \r\n                 95% CI : (0.9489, 0.9668)\r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8409          \r\n                                          \r\n Mcnemar's Test P-Value : 0.006377        \r\n                                          \r\n            Sensitivity : 0.8308          \r\n            Specificity : 0.9829          \r\n         Pos Pred Value : 0.9030          \r\n         Neg Pred Value : 0.9681          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1333          \r\n   Detection Prevalence : 0.1477          \r\n      Balanced Accuracy : 0.9069          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\niii. 🔔Random Forest Train NA✨\r\n\r\nOriginal Dataset with Training Set Missing Value Replaced\r\n\r\nOnly replaced missing values in the training set. The model has 0.9575 in accuracy and 0.8341 in kappa, which improved 📈 compared to the previous model. The recall is 0.8062, which means that this model will misclassify 1 attrited customer of every 10 customers as existing customers.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex2 <- createDataPartition(BankChurners1$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain2 <- BankChurners1[index,]\r\ntest2 <- BankChurners1[-index,]\r\ntable(is.na(train2))\r\n\r\n\r\n\r\n FALSE   TRUE \r\n154407   7633 \r\n\r\nShow code\r\n\r\n# replace missing values in the training set\r\ntrain2 <- VIM::kNN(train2, \r\n              variable = c(\"Dependent_count\", \"Education_Level\", \r\n                          \"Marital_Status\", \"Income_Level\", \r\n                          \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\",\r\n                          \"Total_Revolving_Bal\", \"Total_Amt_Chng_Q4_Q1\",\r\n                          \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\"),\r\n             k = 10)\r\n# summary(train2)\r\ntrain2 <- train2[,-c(21:30)]\r\ntable(is.na(train2))\r\n\r\n\r\n\r\n FALSE \r\n162040 \r\n\r\nShow code\r\n\r\n# train2\r\nchurn_RF2 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train2,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF2\r\n\r\n# test1\r\nchurn_RF_pred2 <- predict(churn_RF2, test, type = \"prob\")\r\nchurn_RF_test_pred2 <- cbind(churn_RF_pred2, test)\r\nchurn_RF_test_pred2 <- churn_RF_test_pred2 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred2$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             285             1740 \r\n\r\nShow code\r\n\r\n#result1\r\nchurn_matrix2 <- confusionMatrix(factor(churn_RF_test_pred2$prediction), \r\n                                 factor(churn_RF_test_pred2$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix2\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             1677               63\r\n  AttritedCustomer               23              262\r\n                                          \r\n               Accuracy : 0.9575          \r\n                 95% CI : (0.9478, 0.9659)\r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8341          \r\n                                          \r\n Mcnemar's Test P-Value : 2.605e-05       \r\n                                          \r\n            Sensitivity : 0.8062          \r\n            Specificity : 0.9865          \r\n         Pos Pred Value : 0.9193          \r\n         Neg Pred Value : 0.9638          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1294          \r\n   Detection Prevalence : 0.1407          \r\n      Balanced Accuracy : 0.8963          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix2$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"plum1\", \r\n                       na.value = \"gray\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"In 35 Days\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\niv. ⛄Random Forest Total NA & SMOTE❄️\r\n\r\nOriginal Dataset with Total Missing Value Replaced and Resampling in the Training Set\r\n\r\nThe model has 0.9549 of accuracy and 0.8423 in kappa, which is similar to the previous model. The recall is 0.9344, the highest score among other models.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train3\r\nchurn_RF3 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE,\r\n                           sampling = \"smote\"),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF3\r\n\r\n# feature importance\r\nvar_imp3 <- varImp(churn_RF3)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp3))\r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n100.00000\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n88.60614\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n48.03891\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n28.33508\r\n\r\n\r\nMonths_Inactive_12_mon\r\n\r\n\r\n26.29738\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n20.91937\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp3, aes(x = reorder(rownames(var_imp3), Overall), y = Overall)) +\r\n  geom_point(color = \"plum1\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp3), xend = rownames(var_imp3), \r\n                   y = 0, yend = Overall), color = \"skyblue\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +\r\n  coord_flip()\r\n\r\n\r\n\r\nShow code\r\n\r\n# test3\r\nchurn_RF_pred3 <- predict(churn_RF3, test, type = \"prob\")\r\nchurn_RF_test_pred3 <- cbind(churn_RF_pred3, test)\r\nchurn_RF_test_pred3 <- churn_RF_test_pred3 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred3$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             561             2477 \r\n\r\nShow code\r\n\r\n# result3\r\nchurn_matrix3 <- confusionMatrix(factor(churn_RF_test_pred3$prediction), \r\n                                 factor(churn_RF_test_pred3$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix3\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2445               32\r\n  AttritedCustomer              105              456\r\n                                          \r\n               Accuracy : 0.9549          \r\n                 95% CI : (0.9469, 0.962) \r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8423          \r\n                                          \r\n Mcnemar's Test P-Value : 7.681e-10       \r\n                                          \r\n            Sensitivity : 0.9344          \r\n            Specificity : 0.9588          \r\n         Pos Pred Value : 0.8128          \r\n         Neg Pred Value : 0.9871          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1501          \r\n   Detection Prevalence : 0.1847          \r\n      Balanced Accuracy : 0.9466          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix3$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"powderblue\", \r\n                       na.value = \"gray\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Let It Snow\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\nv. 🧦🎁Gradient Boosting Tree Total NA🎅🍪🥛\r\n\r\nOriginal Dataset with Total Missing Value Replaced\r\n\r\nThe model has 0.9681 of accuracy and 0.8781 in kappa. The recall is 0.8648 Gradient boosting tree has a better performance compared to the random forest under the same condition.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train4\r\nchurn_GBM1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"gbm\",\r\n  tuneLength = 10,\r\n  verbose = FALSE\r\n)\r\nkable(churn_GBM1$bestTune)\r\n\r\n\r\n\r\n\r\n\r\nn.trees\r\n\r\n\r\ninteraction.depth\r\n\r\n\r\nshrinkage\r\n\r\n\r\nn.minobsinnode\r\n\r\n\r\n58\r\n\r\n\r\n400\r\n\r\n\r\n6\r\n\r\n\r\n0.1\r\n\r\n\r\n10\r\n\r\n\r\nShow code\r\n\r\nplot(churn_GBM1)\r\n\r\n\r\n\r\nShow code\r\n\r\n# test4\r\nchurn_GBM_pred1 <- predict(churn_GBM1, test, type = \"prob\")\r\nchurn_GBM_test_pred1 <- cbind(churn_GBM_pred1, test)\r\nchurn_GBM_test_pred1 <- churn_GBM_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_GBM_test_pred1$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             453             2585 \r\n\r\nShow code\r\n\r\n# result4\r\nchurn_matrix4 <- confusionMatrix(factor(churn_GBM_test_pred1$prediction), \r\n                                 factor(churn_GBM_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix4\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2519               66\r\n  AttritedCustomer               31              422\r\n                                          \r\n               Accuracy : 0.9681          \r\n                 95% CI : (0.9612, 0.974) \r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8781          \r\n                                          \r\n Mcnemar's Test P-Value : 0.0005561       \r\n                                          \r\n            Sensitivity : 0.8648          \r\n            Specificity : 0.9878          \r\n         Pos Pred Value : 0.9316          \r\n         Neg Pred Value : 0.9745          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1389          \r\n   Detection Prevalence : 0.1491          \r\n      Balanced Accuracy : 0.9263          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix4$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"pink\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Christmas is Coming\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\nShow code\r\n\r\n# feature importance\r\n# summary(churn_GBM)\r\nvar_imp4 <- varImp(churn_GBM1, n.trees = 500)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp4))\r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n100.00000\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n76.73888\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n37.50356\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n36.73745\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n22.00470\r\n\r\n\r\nCustomer_Age\r\n\r\n\r\n13.55025\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp4, aes(x = reorder(rownames(var_imp4), Overall), y = Overall)) +\r\n  geom_point(color = \"violet\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp4), xend = rownames(var_imp4), \r\n                   y = 0, yend = Overall), color = \"skyblue\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +  \r\n  coord_flip()\r\n\r\n\r\n\r\n\r\nvi. 🔔Gradient Boosting Tree Train NA✨\r\n\r\nOriginal Dataset with Training Set Missing Value Replaced and only replaced missing values in the training set\r\n\r\nThe model has 0.9691 of accuracy and 0.8805 in kappa, and recall is 0.8545\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex2 <- createDataPartition(BankChurners1$Attrition_Flag, \r\n                              p = .7, list = FALSE, times = 1)\r\n train2 <- BankChurners1[index,]\r\n test2 <- BankChurners1[-index,]\r\n table(is.na(train2))\r\n\r\n\r\n\r\n FALSE   TRUE \r\n134959   6821 \r\n\r\nShow code\r\n\r\n# replace missing values in the training set\r\ntrain2 <- VIM::kNN(train2, \r\n               variable = c(\"Dependent_count\", \"Education_Level\", \r\n                           \"Marital_Status\", \"Income_Level\", \r\n                           \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\",\r\n                           \"Total_Revolving_Bal\", \"Total_Amt_Chng_Q4_Q1\",\r\n                           \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\"),\r\n              k = 10)\r\n# summary(train2)\r\ntrain2 <- train2[,-c(21:30)]\r\ntable(is.na(train2))\r\n\r\n\r\n\r\n FALSE \r\n141780 \r\n\r\nShow code\r\n\r\n# train5\r\nchurn_GBM2 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train2,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"gbm\",\r\n  tuneLength = 10,\r\n  verbose = FALSE\r\n)\r\n# churn_GBM2\r\nkable(churn_GBM2$bestTune)\r\n\r\n\r\n\r\n\r\n\r\nn.trees\r\n\r\n\r\ninteraction.depth\r\n\r\n\r\nshrinkage\r\n\r\n\r\nn.minobsinnode\r\n\r\n\r\n89\r\n\r\n\r\n450\r\n\r\n\r\n9\r\n\r\n\r\n0.1\r\n\r\n\r\n10\r\n\r\n\r\nShow code\r\n\r\nplot(churn_GBM2)\r\n\r\n\r\n\r\nShow code\r\n\r\n# test5\r\nchurn_GBM_pred2 <- predict(churn_GBM2, test, type = \"prob\")\r\nchurn_GBM_test_pred2 <- cbind(churn_GBM_pred2, test2)\r\nchurn_GBM_test_pred2 <- churn_GBM_test_pred2 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_GBM_test_pred2$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             440             2598 \r\n\r\nShow code\r\n\r\n# result5\r\nchurn_matrix5 <- confusionMatrix(factor(churn_GBM_test_pred2$prediction), \r\n                                 factor(churn_GBM_test_pred2$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix5\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2527               71\r\n  AttritedCustomer               23              417\r\n                                          \r\n               Accuracy : 0.9691          \r\n                 95% CI : (0.9623, 0.9749)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8805          \r\n                                          \r\n Mcnemar's Test P-Value : 1.249e-06       \r\n                                          \r\n            Sensitivity : 0.8545          \r\n            Specificity : 0.9910          \r\n         Pos Pred Value : 0.9477          \r\n         Neg Pred Value : 0.9727          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1373          \r\n   Detection Prevalence : 0.1448          \r\n      Balanced Accuracy : 0.9227          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix5$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"lavender\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Fruit Cake\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\nvii. 🦌Gradient Boosting Tree Total NA & SMOTE🥕\r\n\r\nOriginal Dataset with Total Missing Value Replaced and Resampling in the Training Set\r\n\r\nThe model has 0.9635 of accuracy and 0.8668 in kappa, which is similar to the previous result. The recall is 0.9078 🎉 (Mcnemar’s Test P-Value : 0.02545 🅿)\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train6\r\nchurn_GBM3 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE,\r\n                           sampling = \"smote\"),\r\n  method = \"gbm\",\r\n  tuneLength = 10,\r\n  verbose = FALSE\r\n)\r\n# kable(churn_GBM3$bestTune)\r\n# plot(churn_GBM3)\r\n\r\n# test6\r\nchurn_GBM_pred3 <- predict(churn_GBM3, test, type = \"prob\")\r\nchurn_GBM_test_pred3 <- cbind(churn_GBM_pred3, test)\r\nchurn_GBM_test_pred3 <- churn_GBM_test_pred3 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_GBM_test_pred3$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             509             2529 \r\n\r\nShow code\r\n\r\n# result6\r\nchurn_matrix6 <- confusionMatrix(factor(churn_GBM_test_pred3$prediction), \r\n                                 factor(churn_GBM_test_pred3$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix6\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2484               45\r\n  AttritedCustomer               66              443\r\n                                          \r\n               Accuracy : 0.9635          \r\n                 95% CI : (0.9562, 0.9698)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2e-16         \r\n                                          \r\n                  Kappa : 0.8668          \r\n                                          \r\n Mcnemar's Test P-Value : 0.05765         \r\n                                          \r\n            Sensitivity : 0.9078          \r\n            Specificity : 0.9741          \r\n         Pos Pred Value : 0.8703          \r\n         Neg Pred Value : 0.9822          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1458          \r\n   Detection Prevalence : 0.1675          \r\n      Balanced Accuracy : 0.9410          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix6$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"firebrick\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Joy\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\nShow code\r\n\r\n# feature importance\r\n# summary(churn_GBM)\r\nvar_imp5 <- varImp(churn_GBM3, n.trees = 500)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp5))\r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n100.000000\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n35.435463\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n18.702990\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n17.822868\r\n\r\n\r\nMonths_Inactive_12_mon\r\n\r\n\r\n14.611434\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n9.309401\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp4, aes(x = reorder(rownames(var_imp5), Overall), y = Overall)) +\r\n  geom_point(color = \"powderblue\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp5), xend = rownames(var_imp5), \r\n                   y = 0, yend = Overall), color = \"plum1\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +  \r\n  coord_flip()\r\n\r\n\r\n\r\n\r\nviii. 🌜Neural Network🕊️\r\n\r\nOriginal Dataset with Total Missing Value Replaced\r\n\r\nThe model has 0.9351 of accuracy and 0.7446 in kappa, and recall is 0.7277😕. The ROC curve looks great🏄\r\n\r\n\r\nShow code\r\n\r\n# train7\r\nchurn_NNET <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProb =TRUE),\r\n  method = \"nnet\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 5,\r\n  trace= FALSE\r\n)\r\nplot(churn_NNET)\r\n\r\n\r\n\r\nShow code\r\n\r\n# test7\r\nchurn_NNET_pred <- predict(churn_NNET, test, type = \"prob\")\r\nchurn_NNET_test_pred <- cbind(churn_NNET_pred, test)\r\nchurn_NNET_test_pred <- churn_NNET_test_pred %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_NNET_test_pred$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             559             3491 \r\n\r\nShow code\r\n\r\nroc_NNET <- pROC::roc(factor(churn_NNET_test_pred$Attrition_Flag), \r\n                      churn_NNET_test_pred$ExistingCustomer)\r\nplot(roc_NNET)\r\n\r\n\r\n\r\nShow code\r\n\r\n# result7\r\nchurn_matrix7 <- confusionMatrix(factor(churn_NNET_test_pred$prediction), \r\n                                 factor(churn_NNET_test_pred$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix7\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             3314              177\r\n  AttritedCustomer               86              473\r\n                                          \r\n               Accuracy : 0.9351          \r\n                 95% CI : (0.927, 0.9425) \r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.7446          \r\n                                          \r\n Mcnemar's Test P-Value : 2.863e-08       \r\n                                          \r\n            Sensitivity : 0.7277          \r\n            Specificity : 0.9747          \r\n         Pos Pred Value : 0.8462          \r\n         Neg Pred Value : 0.9493          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1168          \r\n   Detection Prevalence : 0.1380          \r\n      Balanced Accuracy : 0.8512          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix7$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"plum1\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Somewhere in My Memory\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\nVI. Result\r\nOverall, 🌳random forest model has better performance🏆 than gradient boosting tree🌲, especially after replacing total missing values and using SMOTE to fix 🔧 the imbalanced dataset issue. (iv.RF TOTAL NA & SMOTE)\r\n\r\n\r\nShow code\r\n\r\ncomparison <- matrix(c(0.9661, 0.8683, 0.8381, 0.9585, 0.8409, 0.8308, 0.9575, 0.8341, \r\n                       0.8062, 0.9549, 0.8423, 0.9344, 0.9681, 0.8781, 0.8648, 0.9691,  \r\n                       0.8805, 0.8545, 0.9635, 0.8668, 0.9078, 0.9351, 0.7446, 0.7277),\r\n                     ncol = 3, byrow = TRUE)\r\ncolnames(comparison) <- c(\"Accuracy\", \"Kappa\", \"Recall\")\r\nrownames(comparison) <- c(\"i.RF TOTAL NA\", \"ii.RF TOTAL NA & VAR\", \"iii.RF TRAIN NA\", \r\n                          \"iv.RF TOTAL NA & SMOTE\", \"v.GBT TOTAL NA\", \"vi.GBT TRAIN NA\", \r\n                          \"vii.GBT TOTAL NA & SMOTE\", \"viii.NNET TOTAL NA\")\r\ncomparison <- as.data.frame.matrix(comparison)\r\nkable(comparison) %>% \r\n  row_spec(4, color = \"white\", background = \"#bdaeea\")\r\n\r\n\r\n\r\n\r\n\r\nAccuracy\r\n\r\n\r\nKappa\r\n\r\n\r\nRecall\r\n\r\n\r\ni.RF TOTAL NA\r\n\r\n\r\n0.9661\r\n\r\n\r\n0.8683\r\n\r\n\r\n0.8381\r\n\r\n\r\nii.RF TOTAL NA & VAR\r\n\r\n\r\n0.9585\r\n\r\n\r\n0.8409\r\n\r\n\r\n0.8308\r\n\r\n\r\niii.RF TRAIN NA\r\n\r\n\r\n0.9575\r\n\r\n\r\n0.8341\r\n\r\n\r\n0.8062\r\n\r\n\r\niv.RF TOTAL NA & SMOTE\r\n\r\n\r\n0.9549\r\n\r\n\r\n0.8423\r\n\r\n\r\n0.9344\r\n\r\n\r\nv.GBT TOTAL NA\r\n\r\n\r\n0.9681\r\n\r\n\r\n0.8781\r\n\r\n\r\n0.8648\r\n\r\n\r\nvi.GBT TRAIN NA\r\n\r\n\r\n0.9691\r\n\r\n\r\n0.8805\r\n\r\n\r\n0.8545\r\n\r\n\r\nvii.GBT TOTAL NA & SMOTE\r\n\r\n\r\n0.9635\r\n\r\n\r\n0.8668\r\n\r\n\r\n0.9078\r\n\r\n\r\nviii.NNET TOTAL NA\r\n\r\n\r\n0.9351\r\n\r\n\r\n0.7446\r\n\r\n\r\n0.7277\r\n\r\n\r\nThe original model from Kaggle has 62% of recall, so 🤠my models did improve the performance of predicting churned customers🥳. So it can help companies to identify potential customer churn. The neural network model is no good or messed up something. Based on the variable importance rates, customers’ transaction numbers and amounts, changes in transaction amount, and total product held by customers are the most important⭐ predicting variables in those models. The demographic factors are not important in those models though.\r\n\r\nhttps://www.kaggle.com/sakshigoyal7/credit-card-customers↩︎\r\nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222916↩︎\r\nhttps://en.wikipedia.org/wiki/Gradient_boosting↩︎\r\n",
      "last_modified": "2021-11-27T09:48:09-06:00"
    },
    {
      "path": "index.html",
      "title": "Siwei Jiang",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          \r\n          \r\n          Siwei Jiang\r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          Resume\r\n          \r\n          \r\n          Project\r\n           \r\n          ▾\r\n          \r\n          \r\n          Rsquared\r\n          Machine Learning\r\n          Final Project\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            Siwei Jiang\r\n          \r\n          \r\n            \r\n              Hello, I am a master student studying accounting in Mississippi State University. Hope one day I can be a 🧭mountaineer🧗🚵️🌋🌄️🗻🚞 “Because IT’s there” \r\n            \r\n            \r\n              Hello, I am a master student studying accounting in Mississippi State University. Hope one day I can be a 🧭mountaineer🧗🚵️🌋🌄️🗻🚞 “Because IT’s there” \r\n            \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                      Github\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Blog\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                    Github\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Email\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Blog\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2021-11-27T09:48:10-06:00"
    },
    {
      "path": "ml.html",
      "title": "Machine Learning",
      "description": "[Support Vector Machines](https://professor-hunt.github.io/ACC8143/Support_Vector_Machine.html){target=\"_blank\"} \n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nI. The Model\r\nII. The Process and Results\r\nIII. Application\r\nIV. Code\r\ni. Data Split 75:25\r\nii. Data Split 50:50\r\niii. Kernel: svmPoly\r\n\r\n\r\nI. The Model\r\n👩‍💻A Support Vector Machine (SVM) model is a supervised👀 machine learning model used for classification. It is simple but very useful. It uses a tool🔨 called hyperplane to separate data into different groups. It has different methods for both linear and non-linear data. And the methods that are used here are svmLinear and svmPloy.\r\nII. The Process and Results\r\nSince SVM is a supervised model, the first step is to split the dataset into training and testing sets and assume the dataset is clean♻️. After the dataset split, we run🏃 the SVM in the training set and use the trained data to predict the testing set. Finally, we use a 📐📏confusion matrix to show how well is our prediction in terms of accuracy, recall, Specificity, etc.\r\nWe are 🔭interested in the effect of data split ratios on the model performance, so we compare two new ratios, 75:25 and 50:50 with the original ratio of 60:40 conducted by Dr.Hunt. We also implement both linear and poly methods on the dataset to see the difference in their performance.\r\nThe result for both splits and poly method are better📈 than the original model performance, which means that data split does have an impact on the model fitness. 🎊Because we know that two classes of variables have some overlaps, so it is expected that poly will be a better fit for the dataset. However, we did not test statistical significance for those changes🙊.\r\n\r\n\r\nShow code\r\n\r\ncomparison <- matrix(c(0.9333, 0.9000, 0.7938, 0.8500, 0.9444, 0.9167, 0.8333, 1.0000,\r\n                       0.9467, 0.9200, 0.9600, 0.8800, 0.9667, 0.9500, 0.9000, 1.0000),\r\n                    ncol = 4, byrow = TRUE)\r\ncolnames(comparison) <- c(\"Accuracy\", \"Kappa\", \"Recall-Versi\", \"Recall-Virgi\")\r\nrownames(comparison) <- c(\"Linear 60:40\", \"Linear 75:25\", \"Linear 50:50\", \"NonLin 60:40\")\r\ncomparison <- as.data.frame.matrix(comparison)\r\nkable(comparison)\r\n\r\n\r\n\r\n\r\n\r\nAccuracy\r\n\r\n\r\nKappa\r\n\r\n\r\nRecall-Versi\r\n\r\n\r\nRecall-Virgi\r\n\r\n\r\nLinear 60:40\r\n\r\n\r\n0.9333\r\n\r\n\r\n0.9000\r\n\r\n\r\n0.7938\r\n\r\n\r\n0.85\r\n\r\n\r\nLinear 75:25\r\n\r\n\r\n0.9444\r\n\r\n\r\n0.9167\r\n\r\n\r\n0.8333\r\n\r\n\r\n1.00\r\n\r\n\r\nLinear 50:50\r\n\r\n\r\n0.9467\r\n\r\n\r\n0.9200\r\n\r\n\r\n0.9600\r\n\r\n\r\n0.88\r\n\r\n\r\nNonLin 60:40\r\n\r\n\r\n0.9667\r\n\r\n\r\n0.9500\r\n\r\n\r\n0.9000\r\n\r\n\r\n1.00\r\n\r\n\r\nIII. Application\r\nThe SVM model can be used for identifying abnormalities such as fraudulent transactions, material misstatements, bankruptcies, abnormal reserves, etc. Auditors can utilize this machine learning model with other algorithms as well as financial ratios to improve their accuracy and efficiency.\r\nIV. Code\r\ni. Data Split 75:25\r\nAccuracy and Kappa both increased a little✨ bit\r\nData Preparation\r\n\r\n\r\nShow code\r\n\r\n# data split\r\niris1 <- iris\r\ntrain_index <- createDataPartition(iris1$Species, p = .75, list = FALSE, times = 1)\r\n\r\niris_train <- iris1[train_index,]\r\niris_test <- iris1[-train_index,]\r\n\r\n\r\n\r\nModel\r\n\r\n\r\nShow code\r\n\r\n# train\r\niris_svm_train <- train(\r\n  form = factor(Species) ~.,\r\n  data = iris_train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"svmLinear\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10\r\n)\r\n# iris_svm_train\r\nsummary(iris_svm_train)\r\n\r\n\r\nLength  Class   Mode \r\n     1   ksvm     S4 \r\n\r\nShow code\r\n\r\n# predict\r\niris_svm_predict <- predict(iris_svm_train, iris_test, type = \"prob\")\r\n\r\niris_svm_predict <- cbind(iris_svm_predict, iris_test)\r\niris_svm_predict <- iris_svm_predict %>% \r\n  mutate(prediction = if_else(setosa > versicolor & setosa > virginica, \"setosa\",\r\n                              if_else(versicolor > setosa & versicolor > virginica, \"versicolor\",\r\n                                      if_else(virginica > setosa & virginica > versicolor, \"virginica\", \"PROBLEM\"))))\r\n# table(iris_svm_predict$prediction)\r\nconfusionMatrix(factor(iris_svm_predict$prediction), factor(iris_svm_predict$Species))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         12          0         0\r\n  versicolor      0         10         0\r\n  virginica       0          2        12\r\n\r\nOverall Statistics\r\n                                          \r\n               Accuracy : 0.9444          \r\n                 95% CI : (0.8134, 0.9932)\r\n    No Information Rate : 0.3333          \r\n    P-Value [Acc > NIR] : 1.728e-14       \r\n                                          \r\n                  Kappa : 0.9167          \r\n                                          \r\n Mcnemar's Test P-Value : NA              \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            0.8333           1.0000\r\nSpecificity                 1.0000            1.0000           0.9167\r\nPos Pred Value              1.0000            1.0000           0.8571\r\nNeg Pred Value              1.0000            0.9231           1.0000\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.2778           0.3333\r\nDetection Prevalence        0.3333            0.2778           0.3889\r\nBalanced Accuracy           1.0000            0.9167           0.9583\r\n\r\nPlot SVM\r\n\r\n\r\nShow code\r\n\r\nsv1 <- iris_train[iris_svm_train$finalModel@SVindex,]\r\n\r\nggplot(data = iris_test, mapping = aes(x = Sepal.Width, y= Petal.Width, color = Species)) +\r\n  geom_point(alpha = .5) +\r\n  geom_point(data = iris_svm_predict, mapping = aes(x = Sepal.Width, y = Petal.Width, color = prediction), \r\n             shape = 6, size = 3) +\r\n  geom_point(data = sv1, mapping = aes(x = Sepal.Width, y = Petal.Width), shape = 4, size = 4) +\r\n  theme(legend.title = element_blank()) +\r\n  ggtitle(\"Support Vector Machine\")\r\n\r\n\r\n\r\n\r\nii. Data Split 50:50\r\nAccuracy and Kappa both increased a little. Versicolor’s recall increased a lot👏\r\nModel\r\n\r\n\r\nShow code\r\n\r\n# data split\r\ntrain_index <- createDataPartition(iris1$Species, p = .5, list = FALSE, times = 1)\r\n\r\niris_train <- iris1[train_index,]\r\niris_test <- iris1[-train_index,]\r\n\r\n# train\r\niris_svm_train <- train(\r\n  form = factor(Species) ~.,\r\n  data = iris_train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"svmLinear\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10\r\n)\r\n# iris_svm_train\r\nsummary(iris_svm_train)\r\n\r\n\r\nLength  Class   Mode \r\n     1   ksvm     S4 \r\n\r\nShow code\r\n\r\n# predict\r\niris_svm_predict <- predict(iris_svm_train, iris_test, type = \"prob\")\r\n\r\niris_svm_predict <- cbind(iris_svm_predict, iris_test)\r\niris_svm_predict <- iris_svm_predict %>% \r\n  mutate(prediction = if_else(setosa > versicolor & setosa > virginica, \"setosa\",\r\n                              if_else(versicolor > setosa & versicolor > virginica, \"versicolor\",\r\n                                      if_else(virginica > setosa & virginica > versicolor, \"virginica\", \"PROBLEM\"))))\r\n# table(iris_svm_predict$prediction)\r\nconfusionMatrix(factor(iris_svm_predict$prediction), factor(iris_test$Species))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         25          0         0\r\n  versicolor      0         24         3\r\n  virginica       0          1        22\r\n\r\nOverall Statistics\r\n                                         \r\n               Accuracy : 0.9467         \r\n                 95% CI : (0.869, 0.9853)\r\n    No Information Rate : 0.3333         \r\n    P-Value [Acc > NIR] : < 2.2e-16      \r\n                                         \r\n                  Kappa : 0.92           \r\n                                         \r\n Mcnemar's Test P-Value : NA             \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            0.9600           0.8800\r\nSpecificity                 1.0000            0.9400           0.9800\r\nPos Pred Value              1.0000            0.8889           0.9565\r\nNeg Pred Value              1.0000            0.9792           0.9423\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.3200           0.2933\r\nDetection Prevalence        0.3333            0.3600           0.3067\r\nBalanced Accuracy           1.0000            0.9500           0.9300\r\n\r\niii. Kernel: svmPoly\r\nHas the 🏆best overall and individual class performance\r\nModel\r\n\r\n\r\nShow code\r\n\r\ntrain_index <- createDataPartition(iris1$Species, p = .6, list = FALSE, times = 1)\r\n\r\niris_train <- iris1[train_index,]\r\niris_test <- iris1[-train_index,]\r\n\r\n# train\r\niris_svm_train <- train(\r\n  form = factor(Species) ~.,\r\n  data = iris_train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"svmPoly\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10\r\n)\r\nsummary(iris_svm_train)\r\n\r\n\r\nLength  Class   Mode \r\n     1   ksvm     S4 \r\n\r\nShow code\r\n\r\n# predict\r\niris_svm_predict <- predict(iris_svm_train, iris_test, type = \"prob\")\r\niris_svm_predict <- cbind(iris_svm_predict, iris_test)\r\n\r\niris_svm_predict <- iris_svm_predict %>% \r\n  mutate(prediction = if_else(setosa > versicolor & setosa > virginica, \"setosa\",\r\n                              if_else(versicolor >setosa & versicolor > virginica, \"versicolor\",\r\n                                      if_else(virginica > setosa & virginica > versicolor, \"virginica\", \"PROBLEM\"))))\r\n# table(iris_svm_predict$prediction)\r\nconfusionMatrix(factor(iris_svm_predict$prediction), factor(iris_test$Species))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         20          0         0\r\n  versicolor      0         18         0\r\n  virginica       0          2        20\r\n\r\nOverall Statistics\r\n                                          \r\n               Accuracy : 0.9667          \r\n                 95% CI : (0.8847, 0.9959)\r\n    No Information Rate : 0.3333          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.95            \r\n                                          \r\n Mcnemar's Test P-Value : NA              \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            0.9000           1.0000\r\nSpecificity                 1.0000            1.0000           0.9500\r\nPos Pred Value              1.0000            1.0000           0.9091\r\nNeg Pred Value              1.0000            0.9524           1.0000\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.3000           0.3333\r\nDetection Prevalence        0.3333            0.3000           0.3667\r\nBalanced Accuracy           1.0000            0.9500           0.9750\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-27T09:48:15-06:00"
    },
    {
      "path": "resume.html",
      "title": "Résumé",
      "author": [],
      "contents": "\r\n\r\n\r\na {n  \r\n  text-decoration: none; \r\n  color: rgba(121, 205, 205);\r\n}\r\na:hover {\r\n  color: rgba(255, 182, 255, 0.8);\r\n}\r\nul {\r\n  list-style: none; /* Remove list bullets bcz don't know how to change color */\r\n  padding: 0;\r\n  margin: 0;\r\n}\r\nli::before {\r\n  content: \"•\"; \r\n  color: \"#5A59A3\";\r\n}\r\nh1 {\r\n  font-family: candara; /* title */\r\n  font-style: italic;\r\n}\r\nh2 {\r\n  font-family: candara;\r\n  font-style: italic;\r\n  color: rgba(134, 35, 141, 0.72);\r\n}\r\np code,\r\nli code {\r\n    line-height: 2.0; \r\n    white-space: nowrap;\r\n}\r\nbody {\r\n    width: 100vw;\r\n    height: 100vh;\r\n    margin: 0;\r\n    background: linear-gradient(\r\n        130deg, \r\n        #5A59A3, \r\n        #C66060\r\n    ) no-repeat  fixed;\r\n}\r\n\r\nEducation\r\nMaster in Taxation: Adkerson School of Accountancy Expected Graduattion Date\r\nBachelor of Business in Accounting: Adkerson School of Accountancy May 2020\r\nMinor in Business Analytics\r\nMississippi State University, Mississippi State, MS\r\nWorking Experience\r\n  Private Accountant for a Fire Protection Service CompanyFall 2014 – Fall 2015\r\n  Hunan, China\r\n              Journal entries and general ledger preparation\r\n              Bank statements and reconciliation\r\n              Examining expenses submitted by the construction manager\r\n              Taxation preparation during tax season\r\nCourse Group Projects\r\n  PowerPoint and social platforms: Marketing strategy plans for a drone startup\r\n  Excel and Word: Prepared consolidated financial reports for company acquisition\r\n  R: Bankruptcy analysis. Methods: holdout validation in discriminant analysis and logistic         regression analysis, and cross-validation in decision tree analysis\r\nComputer Skills\r\n  Advanced in Microsoft Office including Excel, Word, and PowerPoint\r\n  Developing knowledge in Access, R, SAS, and Tableau\r\nVolunteer Work\r\n  West Point Clay County Animal Shelter\r\n  MSU Community Garden\r\n  Starkville Community Farmers Market\r\n  The Salvation Army\r\n\r\n\r\n\r\n",
      "last_modified": "2021-11-27T09:48:18-06:00"
    },
    {
      "path": "rsquared.html",
      "title": "R-squared",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nI. Why\r\nII. Time to Blow RSquared Up 💥\r\n1. \\(R^2\\) does not measure goodness of fit.\r\n2. \\(R^2\\) can be arbitrarily close to 1 when the model is totally wrong.\r\n3. \\(R^2\\) says nothing about prediction error\r\n4. \\(R^2\\) can easily go down when the model assumptions are better fulfilled.\r\n5. \\(R^2\\) does not measure how one variable explains another\r\n\r\nIII. So\r\n\r\nI. Why\r\n\r\nIt is easy to manipulate underlying data and make legitimate statements without giving a full context. For analyses/claims that use R-squared, we should be cautious and not interpret it alone as a measure of how well a model fits the data.\r\n\r\nII. Time to Blow RSquared Up1 💥\r\nR-squared is a statistic that often accompanies regression output. It ranges in value from 0 to 1 and is usually interpreted as summarizing the percent of variation in the response that the regression model explains. So an R-squared of 0.65 might mean that the model explains about 65% of the variation in our dependent variable. Given this logic, we prefer our regression models have a high R-squared.\r\nIn R, we typically get R-squared by calling the summary function on a model object. Here’s a quick example using simulated data:\r\n\r\n\r\n# independent variable\r\nx <- 1:20 \r\n# for reproducibility\r\nset.seed(1) \r\n# dependent variable; function of x with random error\r\ny <- 2 + 0.5*x + rnorm(20,0,3) \r\n# simple linear regression\r\nmod <- lm(y~x)\r\n# request just the r-squared value\r\nsummary(mod)$r.squared          \r\n\r\n\r\n[1] 0.6026682\r\n\r\nOne way to express R-squared is as the sum of squared fitted-value deviations divided by the sum of squared original-value deviations:\r\n\\[\r\nR^{2} =  \\frac{\\sum (\\hat{y} – \\bar{\\hat{y}})^{2}}{\\sum (y – \\bar{y})^{2}}\r\n\\]\r\nWe can calculate it directly using our model object like so:\r\n\r\n\r\n# extract fitted (or predicted) values from model\r\nf <- mod$fitted.values\r\n# sum of squared fitted-value deviations\r\nmss <- sum((f - mean(f))^2)\r\n# sum of squared original-value deviations\r\ntss <- sum((y - mean(y))^2)\r\n# r-squared\r\nmss/tss                      \r\n\r\n\r\n[1] 0.6026682\r\n\r\n1. \\(R^2\\) does not measure goodness of fit.\r\nIt can be arbitrarily low when the model is completely correct.* By making\\(σ^2\\) large, we drive R-squared towards 0, even when every assumption of the simple linear regression model is correct in every particular.\r\nWhat is \\(σ^2\\)? When we perform linear regression, we assume our model almost predicts our dependent variable. The difference between “almost” and “exact” is assumed to be a draw from a Normal distribution with mean 0 and some variance we call \\(σ^2\\).\r\nThis statement is easy enough to demonstrate. The way we do it here is to create a function that (1) generates data meeting the assumptions of simple linear regression (independent observations, normally distributed errors with constant variance), (2) fits a simple linear model to the data, and (3) reports the R-squared. Notice the only parameter for sake of simplicity is sigma. We then “apply” this function to a series of increasing \\(σ\\) values and plot the results.\r\n\r\n\r\nr2.0 <- function(sig){\r\n  # our predictor\r\n  x <- seq(1,10,length.out = 100)   \r\n  # our response; a function of x plus some random noise\r\n  y <- 2 + 1.2*x + rnorm(100,0,sd = sig) \r\n  # print the R-squared value\r\n  summary(lm(y ~ x))$r.squared          \r\n}\r\nsigmas <- seq(0.5,20,length.out = 20)\r\n # apply our function to a series of sigma values\r\nrout <- sapply(sigmas, r2.0)            \r\nplot(rout ~ sigmas, type=\"b\")\r\n\r\n\r\n\r\n\r\nR-squared tanks hard with increasing sigma, even though the model is completely correct in every respect.\r\n2. \\(R^2\\) can be arbitrarily close to 1 when the model is totally wrong.\r\nThe point being made is that R-squared does not measure goodness of fit.\r\n\r\n\r\nset.seed(1)\r\n# our predictor is data from an exponential distribution\r\nx <- rexp(50,rate=0.005)\r\n# non-linear data generation\r\ny <- (x-1)^2 * runif(50, min=0.8, max=1.2) \r\n# clearly non-linear\r\nplot(x,y)             \r\n\r\n\r\n\r\n\r\n\r\n\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.8485146\r\n\r\nIt’s very high at about 0.85, but the model is completely wrong. Using R-squared to justify the “goodness” of our model in this instance would be a mistake. Hopefully one would plot the data first and recognize that a simple linear regression in this case would be inappropriate.\r\n3. \\(R^2\\) says nothing about prediction error\r\nEven with* \\(σ^2\\) exactly the same, and no change in the coefficients. R-squared can be anywhere between 0 and 1 just by changing the range of X. We’re better off using Mean Square Error (MSE) as a measure of prediction error.\r\nMSE is basically the fitted y values minus the observed y values, squared, then summed, and then divided by the number of observations.\r\nLet’s demonstrate this statement by first generating data that meets all simple linear regression assumptions and then regressing y on x to assess both R-squared and MSE.\r\n\r\n\r\nx <- seq(1,10,length.out = 100)\r\nset.seed(1)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 0.9)\r\nmod1 <- lm(y ~ x)\r\nsummary(mod1)$r.squared\r\n\r\n\r\n[1] 0.9383379\r\n\r\n# Mean squared error\r\nsum((fitted(mod1) - y)^2)/100\r\n\r\n\r\n[1] 0.6468052\r\n\r\nNow repeat the above code, but this time with a different range of x. Leave everything else the same:\r\n\r\n\r\n # new range of x\r\nx <- seq(1,2,length.out = 100)      \r\nset.seed(1)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 0.9)\r\nmod1 <- lm(y ~ x)\r\nsummary(mod1)$r.squared\r\n\r\n\r\n[1] 0.1502448\r\n\r\n# Mean squared error\r\nsum((fitted(mod1) - y)^2)/100        \r\n\r\n\r\n[1] 0.6468052\r\n\r\nThe R-squared falls from 0.94 to 0.15 but the MSE remains the same. In other words the predictive ability is the same for both data sets, but the R-squared would lead you to believe the first example somehow had a model with more predictive power.\r\n4. \\(R^2\\) can easily go down when the model assumptions are better fulfilled.\r\nLet’s examine this by generating data that would benefit from transformation. Notice the R code below is very much like our previous efforts but now we exponentiate our y variable.\r\n\r\n\r\nx <- seq(1,2,length.out = 100)\r\nset.seed(1)\r\ny <- exp(-2 - 0.09*x + rnorm(100,0,sd = 2.5))\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.003281718\r\n\r\nplot(lm(y ~ x), which=3)\r\n\r\n\r\n\r\n\r\nR-squared is very low and our residuals vs. fitted plot reveals outliers and non-constant variance. A common fix for this is to log transform the data. Let’s try that and see what happens:\r\n\r\n\r\nplot(lm(log(y)~x),which = 3) \r\n\r\n\r\n\r\n\r\nThe diagnostic plot looks much better. Our assumption of constant variance appears to be met. But look at the R-squared:\r\n\r\n\r\nsummary(lm(log(y)~x))$r.squared \r\n\r\n\r\n[1] 0.0006921086\r\n\r\nIt’s even lower! This is an extreme case and it doesn’t always happen like this. In fact, a log transformation will usually produce an increase in R-squared. But as just demonstrated, assumptions that are better fulfilled don’t always lead to higher R-squared.\r\n5. \\(R^2\\) does not measure how one variable explains another\r\nIt is very common to say that R-squared is “the fraction of variance explained” by the regression. \\[Yet\\] if we regressed X on Y, we’d get exactly the same R-squared. This in itself should be enough to show that a high R-squared says nothing about explaining one variable by another.\r\nThis is the easiest statement to demonstrate:\r\n\r\n\r\nx <- seq(1,10,length.out = 100)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 2)\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.737738\r\n\r\nsummary(lm(x ~ y))$r.squared\r\n\r\n\r\n[1] 0.737738\r\n\r\nDoes x explain y, or does y explain x? Are we saying “explain” to dance around the word “cause”? In a simple scenario with two variables such as this, R-squared is simply the square of the correlation between x and y:\r\n\r\n\r\nall.equal(cor(x,y)^2, summary(lm(x ~ y))$r.squared, summary(lm(y ~ x))$r.squared)\r\n\r\n\r\n[1] TRUE\r\n\r\nLet’s recap:\r\nR-squared does not measure goodness of fit.\r\nR-squared does not measure predictive error.\r\nR-squared does not necessarily increase when assumptions are better satisfied.\r\nR-squared does not measure how one variable explains another.\r\nIII. So\r\n\r\nAlthough different fields have different acceptable values for the R-squared, we could just use other measures for goodness of fit like MSE.\r\n\r\n\r\nhttps://data.library.virginia.edu/is-r-squared-useless/↩︎\r\n",
      "last_modified": "2021-11-27T09:48:27-06:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
