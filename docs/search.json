{
  "articles": [
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-01-18T15:06:08-06:00"
    },
    {
      "path": "customer_churn_prediction.html",
      "title": "Customer Churn Prediction",
      "description": "This report is the final project for my accounitng analysis class, and the codes are borrowed from my professor, Dr. Hunt's [course website](https://professor-hunt.github.io/ACC8143/){target=\"_blank\"}.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nI. About the data set\r\nII. Descriptive Stats\r\nIII. The Models\r\nIV. The Process\r\nV. Code\r\ni. 🎄Random Forest Total NA⭐\r\nii. 🌴Random Forest NA & Var🍃\r\niii. Random Forest Train NA✨\r\niv. Random Forest Total NA & SMOTE❄️\r\nv. Gradient Boosting Tree Total NA\r\nvi. Gradient Boosting Tree Train NA✨\r\nvii. Gradient Boosting Tree Total NA & SMOTE\r\nviii. 🌜Neural Network Total NA🕊️\r\nix. Neural Network Total NA & SMOTE\r\n\r\nVI. Result\r\n\r\nI. About the data set\r\nI obtained this data set from Kaggle1, and Sakshi Goyal uploaded it in 2020. This data set is about a 🏦bank’s customer churn issue. The manager💼 of the bank is interested in predicting which customer will leave this bank💸. By doing so, the bank can target those customers with special products and services to increase their satisfaction and customer retention🌞.\r\nIt contains 10,127 observations and 23 variables. Because I had some issues with Income Category values, so I add another column that used a scale of 1 through 5 to represent each income category in Excel before importing it to the Rstudio. My data analyses are based on 20 variables, which excluded the Client Number and two Naive Bayes Classifiers😶.\r\nThe purpose of this project is to predict churned customers, so I use recall as an important model fit measurement📐. I also include accuracy and kappa as measurements of model fitness. I choose kappa because customer churn is only around 16% of total customers. Although some studies state kappa is not a good measure for classification model2, I think it is good enough for this project😎 I include a comparison table📊 in the last section, Result for each models’ performance.\r\nII. Descriptive Stats\r\nThis data set has 9,664 missing values, which is 4.77% of the 202,540 total values. Most of those missing values are belong to categorical variables.\r\nAfter using kNN to replace all the missing data by calculating their nearest 10 neighbors 🏠🏡 values, the new data set contains 0️⃣ missing values. The distribution of the target variable is not balanced⚖️, as attrited customers only represent 16% of the total customers. Because of the potential overfitting issue, I used caret’s built-in function SMOTE oversampling to overcome this issue, and it did improved the model performance. Below are some visualizations that are used for gaining some insights of the underlying data.\r\n\r\n\r\nShow code\r\n\r\nBankChurners1 <- unknownToNA(BankChurners, unknown = c(\"\", \"Unknown\"))\r\n# summary(BankChurners1)\r\nNA_cnt <- table(is.na(BankChurners1))\r\nNA_pct <- prop.table(NA_cnt)\r\ncbind(NA_cnt, NA_pct)\r\n\r\n\r\n      NA_cnt     NA_pct\r\nFALSE 192876 0.95228597\r\nTRUE    9664 0.04771403\r\n\r\nShow code\r\n\r\n# replace all missing values \r\nBankChurners2 <- VIM::kNN(BankChurners1, \r\n                          variable = c(\"Dependent_count\", \"Education_Level\", \r\n                                       \"Marital_Status\", \"Income_Level\", \r\n                                       \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\",\r\n                                       \"Total_Revolving_Bal\", \"Total_Amt_Chng_Q4_Q1\",\r\n                                       \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\"),\r\n                          k = 10)\r\nBankChurners2 <- BankChurners2[, -c(21:30)]\r\ntable(is.na(BankChurners2))\r\n\r\n\r\n\r\n FALSE \r\n202540 \r\n\r\nShow code\r\n\r\nNA_cnt <- table(BankChurners2$Attrition_Flag)\r\nNA_pct <- prop.table(counts)\r\ncbind(NA_cnt, NA_pct)\r\n\r\n\r\n                 NA_cnt     NA_pct\r\nExistingCustomer   8500 0.97059671\r\nAttritedCustomer   1627 0.02940329\r\n\r\n\r\n\r\nTransaction Count Attrited customer group has less variability and less spread regarding the total number of transactions. We can see that 50% of customer churns have less than 50 transaction counts and no of those customers have more than 100 transactions.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1, \r\n       mapping = aes(x = Attrition_Flag, \r\n                     y = Total_Trans_Ct,\r\n                     fill = Attrition_Flag)) +\r\n  labs(title = \"Boxplot: Total Transaction Count\",\r\n       tag = \"Fig. 1\") +\r\n  geom_boxplot(alpha = .3) +\r\n  theme(legend.position = \"none\") +\r\n  scale_fill_brewer(palette = \"Dark2\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nTransaction Amt💵 Both existing and attrited Customers are right-skewed due to outliers regarding their total transaction amounts.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1, \r\n       mapping = aes(x = Attrition_Flag, \r\n                     y = Total_Trans_Amt,\r\n                     fill = Attrition_Flag)) +\r\n  labs(title = \"Boxplot: Total Transaction Amount\",\r\n       tag = \"Fig. 2\") +\r\n  geom_boxplot(alpha = .3) +\r\n  theme(legend.position = \"none\") +\r\n  scale_fill_brewer(palette = \"Accent\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n🌠Credit Limit The majority of attrited customers have lower than $5000 credit.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1,\r\n       mapping = aes(x = Credit_Limit,\r\n                     fill = Attrition_Flag)) +\r\n  geom_histogram(color = \"#e9ecef\", \r\n                 alpha = 1,\r\n                 position = \"stack\") +\r\n  scale_fill_manual(values=c(\"#adb8ff\", \"#e8b5ff\")) +\r\n  theme_ipsum() +\r\n  labs(title = \"Histogram: Credit Limit vs Attrition\",\r\n       tag = \"Fig. 4\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nIncome vs Gender Females’ income levels are concentrated at low levels such as levels 1 and 2 while males have much higher income level distributions.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = BankChurners1,\r\n       mapping = aes(x = Income_Level,\r\n                     group = Gender,\r\n                     fill = Gender)) +\r\n  geom_density(adjust = 1.5, alpha = .4) +\r\n  theme_ipsum() +\r\n  labs(title = \"Density Plot: Gender vs Income Level\",\r\n       tag = \"Fig. 3\") +\r\n  scale_color_manual(values=c(\"M\"=\"blue\", \"F\"=\"pink\")) # not working\r\n\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nkable(IncomeLevel)\r\n\r\n\r\n\r\nIncome_Level\r\n\r\n\r\nIncome_Category\r\n\r\n\r\n1\r\n\r\n\r\nLess than $40K\r\n\r\n\r\n2\r\n\r\n\r\n$40K - $60K\r\n\r\n\r\n3\r\n\r\n\r\n$60K - $80K\r\n\r\n\r\n4\r\n\r\n\r\n$80K - $120K\r\n\r\n\r\n5\r\n\r\n\r\n$120K +\r\n\r\n\r\n\r\n\r\nIII. The Models\r\nThe three models used for this project are as follow:\r\nRandom Forest🌳: Decision trees are sensitive to changes, introducing randomness to each split of trees, reduces the over-fitting issue. Also, random forest uses bagging method to make decisions based on a majority vote from each individual tree.\r\nGradient Boosting Tree🌲: Gradient boosting is normally better💪 than random forest due to its arbitrary cost functions for classification purpose3.\r\nNeural Network🔮: Neural network is very effective and efficient in making inferences and detecting patterns from complex data sets. It uses the input information to optimize the weight of those inputs and then generates outputs. It also minimizes the errors ❌ of those outputs to improve those processed inputs until the errors become small enough🔄. The final result is based on minimized errors❓\r\nIV. The Process\r\nI split the data set into the training set and testing set based on 4 different ratios, and the 7:3 ratio has the best result, so I use this ratio for rest of models: 🌳random forest, gradient boosting tree🌲, and 💫neural network🔮 to train🚋 each data set. After importing the original data set, I use the kNN function with k = 10 to replace those missing values. For comparison, I replace missing values only in the training set and leave the testing set as it is. Both random forest and gradient boosting trees have better performance in terms of recall after re-sampling in the training sets. Neural network model turns out to have the worst performance. I am going to use SOMTE for the neural network model just to see the comparison. It does improved the recall quit bit even though the accuracy decreased a bit. I will update the comparsion table and the result description late.\r\nV. Code\r\ni. 🎄Random Forest Total NA⭐\r\n\r\nOriginal data set with Total Missing Value Replaced\r\n\r\nI use 4 different ratio to split the data set into a training set and a testing set. The 7:3 ratio has the best performance. The model has 0.9661 of accuracy🎯 and 0.8683 in kappa, this huge drop probably is due to the imbalanced distribution of the attrition. The recall is 0.8381, which means that this model will misclassify 2 attrited customers of every 10 customers as existing customers.\r\n\r\n\r\nShow code\r\n\r\ncomparison <- matrix(c(0.9599, 0.8437, 0.8155, 0.9590, 0.8406, 0.8154, 0.9661, 0.8683, 0.8381, 0.9580, 0.8359, 0.8062),\r\n                    ncol = 3, byrow = TRUE)\r\ncolnames(comparison) <- c(\"Accuracy\", \"Kappa\", \"Recall\")\r\nrownames(comparison) <- c(\"5:5\", \"6:4\", \"7:3\", \"8:2\")\r\ncomparison <- as.data.frame.matrix(comparison) \r\nkable(comparison) %>% \r\n  row_spec(3, color = \"white\", background = \"#bdaeea\")\r\n\r\n\r\n\r\n\r\n\r\nAccuracy\r\n\r\n\r\nKappa\r\n\r\n\r\nRecall\r\n\r\n\r\n5:5\r\n\r\n\r\n0.9599\r\n\r\n\r\n0.8437\r\n\r\n\r\n0.8155\r\n\r\n\r\n6:4\r\n\r\n\r\n0.9590\r\n\r\n\r\n0.8406\r\n\r\n\r\n0.8154\r\n\r\n\r\n7:3\r\n\r\n\r\n0.9661\r\n\r\n\r\n0.8683\r\n\r\n\r\n0.8381\r\n\r\n\r\n8:2\r\n\r\n\r\n0.9580\r\n\r\n\r\n0.8359\r\n\r\n\r\n0.8062\r\n\r\n\r\n\r\n\r\n5:5 Data split in 5:5 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .5, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF1\r\n\r\n# feature importance\r\nvar_imp1 <- varImp(churn_RF1)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp1)) \r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n100.00000\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n93.11644\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n63.25446\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n41.57094\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n36.03208\r\n\r\n\r\nTotal_Revolving_Bal\r\n\r\n\r\n32.73355\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp1, aes(x = reorder(rownames(var_imp1), Overall), y = Overall)) +\r\n  geom_point(color = \"plum1\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp1), xend = rownames(var_imp1), \r\n                   y = 0, yend = Overall), color = \"skyblue\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +  \r\n  coord_flip()\r\n\r\n\r\n\r\nShow code\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred1$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             730             4333 \r\n\r\nShow code\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             4201              132\r\n  AttritedCustomer               49              681\r\n                                          \r\n               Accuracy : 0.9643          \r\n                 95% CI : (0.9588, 0.9692)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8617          \r\n                                          \r\n Mcnemar's Test P-Value : 1.094e-09       \r\n                                          \r\n            Sensitivity : 0.8376          \r\n            Specificity : 0.9885          \r\n         Pos Pred Value : 0.9329          \r\n         Neg Pred Value : 0.9695          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1345          \r\n   Detection Prevalence : 0.1442          \r\n      Balanced Accuracy : 0.9131          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\n# Accuracy : 0.9632  Kappa : 0.8586 Sensitivity : 0.8431\r\n\r\nggplot(as.data.frame(churn_matrix1$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"darkgreen\", \r\n                       na.value = \"gray\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Random Forest Confusion Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n6:4 Data split in 6:4 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .6, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF1\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             3354              117\r\n  AttritedCustomer               46              533\r\n                                          \r\n               Accuracy : 0.9598          \r\n                 95% CI : (0.9532, 0.9656)\r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8437          \r\n                                          \r\n Mcnemar's Test P-Value : 4.186e-08       \r\n                                          \r\n            Sensitivity : 0.8200          \r\n            Specificity : 0.9865          \r\n         Pos Pred Value : 0.9206          \r\n         Neg Pred Value : 0.9663          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1316          \r\n   Detection Prevalence : 0.1430          \r\n      Balanced Accuracy : 0.9032          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\n# Accuracy : 0.9632  Kappa : 0.8586 Sensitivity : 0.8431\r\n\r\n\r\n\r\n\r\n\r\n7:3 Data split in 7:3 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF1\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred1$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             444             2594 \r\n\r\nShow code\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2519               75\r\n  AttritedCustomer               31              413\r\n                                          \r\n               Accuracy : 0.9651          \r\n                 95% CI : (0.958, 0.9713) \r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8657          \r\n                                          \r\n Mcnemar's Test P-Value : 2.96e-05        \r\n                                          \r\n            Sensitivity : 0.8463          \r\n            Specificity : 0.9878          \r\n         Pos Pred Value : 0.9302          \r\n         Neg Pred Value : 0.9711          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1359          \r\n   Detection Prevalence : 0.1461          \r\n      Balanced Accuracy : 0.9171          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\n\r\n\r\n8:2 Data split in 8:2 ratio.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .8, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train1\r\nchurn_RF1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n\r\n# test1\r\nchurn_RF_pred1 <- predict(churn_RF1, test, type = \"prob\")\r\nchurn_RF_test_pred1 <- cbind(churn_RF_pred1, test)\r\nchurn_RF_test_pred1 <- churn_RF_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\n\r\n# result1\r\nchurn_matrix1 <- confusionMatrix(factor(churn_RF_test_pred1$prediction), \r\n                                 factor(churn_RF_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix1\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             1683               41\r\n  AttritedCustomer               17              284\r\n                                          \r\n               Accuracy : 0.9714          \r\n                 95% CI : (0.9631, 0.9782)\r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8904          \r\n                                          \r\n Mcnemar's Test P-Value : 0.002527        \r\n                                          \r\n            Sensitivity : 0.8738          \r\n            Specificity : 0.9900          \r\n         Pos Pred Value : 0.9435          \r\n         Neg Pred Value : 0.9762          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1402          \r\n   Detection Prevalence : 0.1486          \r\n      Balanced Accuracy : 0.9319          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\n\r\n\r\nii. 🌴Random Forest NA & Var🍃\r\n\r\ndata set with 14 variables and Total Missing Value Replaced\r\n\r\nEducation level🎓, marital status💑, card category💳, income level💰, dependent count👶, and gender👦 👩 are the least important variables that used for the final prediction. After dropping those 6 variables, the model performance decreased a little bit compared to the previous model’s.\r\n\r\n\r\nShow code\r\n\r\n# data split drop 6 var\r\nBankChurners_drop_var <- BankChurners2[-c(3:8)]\r\nindex_var <- createDataPartition(BankChurners_drop_var$Attrition_Flag, \r\n                                 p = .7, list = FALSE, times = 1)\r\ntrain_var <- BankChurners_drop_var[index,]\r\ntest_var <- BankChurners_drop_var[-index,]\r\n\r\n# train drop 6 var\r\nchurn_RF_var <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train_var,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF_var\r\n\r\n# test drop 6 var\r\nchurn_RF_pred_var <- predict(churn_RF_var, test_var, type = \"prob\")\r\nchurn_RF_test_pred_var <- cbind(churn_RF_pred_var, test_var)\r\nchurn_RF_test_pred_var <- churn_RF_test_pred_var %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred_var$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             299             1726 \r\n\r\nShow code\r\n\r\n# result drop 6 var\r\nchurn_matrix_var <- confusionMatrix(factor(churn_RF_test_pred_var$prediction), \r\n                                    factor(churn_RF_test_pred_var$Attrition_Flag), \r\n                                    positive = \"AttritedCustomer\")\r\nchurn_matrix_var\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             1682               44\r\n  AttritedCustomer               18              281\r\n                                          \r\n               Accuracy : 0.9694          \r\n                 95% CI : (0.9609, 0.9764)\r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8826          \r\n                                          \r\n Mcnemar's Test P-Value : 0.001498        \r\n                                          \r\n            Sensitivity : 0.8646          \r\n            Specificity : 0.9894          \r\n         Pos Pred Value : 0.9398          \r\n         Neg Pred Value : 0.9745          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1388          \r\n   Detection Prevalence : 0.1477          \r\n      Balanced Accuracy : 0.9270          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\niii. Random Forest Train NA✨\r\n\r\nOriginal data set with Training Set Missing Value Replaced\r\n\r\nOnly replaced missing values in the training set. The model has 0.9575 in accuracy and 0.8341 in kappa, which improved 📈 compared to the previous model. The recall is 0.8062, which means that this model will misclassify 1 attrited customer of every 10 customers as existing customers.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex2 <- createDataPartition(BankChurners1$Attrition_Flag, \r\n                              p = .7, list = FALSE, times = 1)\r\ntrain2 <- BankChurners1[index,]\r\ntest2 <- BankChurners1[-index,]\r\ntable(is.na(train2))\r\n\r\n\r\n\r\n FALSE   TRUE \r\n154354   7686 \r\n\r\nShow code\r\n\r\n# replace missing values in the training set\r\ntrain2 <- VIM::kNN(train2, \r\n                   variable = c(\"Dependent_count\", \"Education_Level\", \r\n                                \"Marital_Status\", \"Income_Level\", \r\n                                \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\",\r\n                                \"Total_Revolving_Bal\", \"Total_Amt_Chng_Q4_Q1\",\r\n                                \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\"),\r\n                   k = 10)\r\n# summary(train2)\r\ntrain2 <- train2[, -c(21:30)]\r\ntable(is.na(train2))\r\n\r\n\r\n\r\n FALSE \r\n162040 \r\n\r\nShow code\r\n\r\n# train2\r\nchurn_RF2 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train2,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF2\r\n\r\n# test1\r\nchurn_RF_pred2 <- predict(churn_RF2, test, type = \"prob\")\r\nchurn_RF_test_pred2 <- cbind(churn_RF_pred2, test)\r\nchurn_RF_test_pred2 <- churn_RF_test_pred2 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred2$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             301             1724 \r\n\r\nShow code\r\n\r\n#result1\r\nchurn_matrix2 <- confusionMatrix(factor(churn_RF_test_pred2$prediction), \r\n                                 factor(churn_RF_test_pred2$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix2\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             1682               42\r\n  AttritedCustomer               18              283\r\n                                          \r\n               Accuracy : 0.9704          \r\n                 95% CI : (0.962, 0.9773) \r\n    No Information Rate : 0.8395          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8867          \r\n                                          \r\n Mcnemar's Test P-Value : 0.002985        \r\n                                          \r\n            Sensitivity : 0.8708          \r\n            Specificity : 0.9894          \r\n         Pos Pred Value : 0.9402          \r\n         Neg Pred Value : 0.9756          \r\n             Prevalence : 0.1605          \r\n         Detection Rate : 0.1398          \r\n   Detection Prevalence : 0.1486          \r\n      Balanced Accuracy : 0.9301          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix2$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"plum1\", \r\n                       na.value = \"gray\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Random Forest Confusion Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\niv. Random Forest Total NA & SMOTE❄️\r\n\r\nOriginal data set with Total Missing Value Replaced and Resampling in the Training Set\r\n\r\nThe model has 0.9549 of accuracy and 0.8423 in kappa, which is similar to the previous model. The recall is 0.9344, the highest score among other models.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train3\r\nchurn_RF3 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE,\r\n                           sampling = \"smote\"),\r\n  method = \"rf\",\r\n  tuneLength = 10\r\n)\r\n# churn_RF3\r\n\r\n# feature importance\r\nvar_imp3 <- varImp(churn_RF3)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp3))\r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n100.00000\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n71.55841\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n35.62309\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n26.05581\r\n\r\n\r\nMonths_Inactive_12_mon\r\n\r\n\r\n19.63056\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n14.54063\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp3, aes(x = reorder(rownames(var_imp3), Overall), y = Overall)) +\r\n  geom_point(color = \"plum1\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp3), xend = rownames(var_imp3), \r\n                   y = 0, yend = Overall), color = \"skyblue\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +\r\n  coord_flip()\r\n\r\n\r\n\r\nShow code\r\n\r\n# test3\r\nchurn_RF_pred3 <- predict(churn_RF3, test, type = \"prob\")\r\nchurn_RF_test_pred3 <- cbind(churn_RF_pred3, test)\r\nchurn_RF_test_pred3 <- churn_RF_test_pred3 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_RF_test_pred3$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             552             2486 \r\n\r\nShow code\r\n\r\n# result3\r\nchurn_matrix3 <- confusionMatrix(factor(churn_RF_test_pred3$prediction), \r\n                                 factor(churn_RF_test_pred3$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix3\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2448               38\r\n  AttritedCustomer              102              450\r\n                                          \r\n               Accuracy : 0.9539          \r\n                 95% CI : (0.9458, 0.9611)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8377          \r\n                                          \r\n Mcnemar's Test P-Value : 1.012e-07       \r\n                                          \r\n            Sensitivity : 0.9221          \r\n            Specificity : 0.9600          \r\n         Pos Pred Value : 0.8152          \r\n         Neg Pred Value : 0.9847          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1481          \r\n   Detection Prevalence : 0.1817          \r\n      Balanced Accuracy : 0.9411          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix3$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"powderblue\", \r\n                       na.value = \"gray\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Random Forest & SMOTE Confusino Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\nv. Gradient Boosting Tree Total NA\r\n\r\nOriginal data set with Total Missing Value Replaced\r\n\r\nThe model has 0.9681 of accuracy and 0.8781 in kappa. The recall is 0.8648 Gradient boosting tree has a better performance compared to the random forest under the same condition.\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train4\r\nchurn_GBM1 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"gbm\",\r\n  tuneLength = 10,\r\n  verbose = FALSE\r\n)\r\nkable(churn_GBM1$bestTune)\r\n\r\n\r\n\r\n\r\n\r\nn.trees\r\n\r\n\r\ninteraction.depth\r\n\r\n\r\nshrinkage\r\n\r\n\r\nn.minobsinnode\r\n\r\n\r\n60\r\n\r\n\r\n500\r\n\r\n\r\n6\r\n\r\n\r\n0.1\r\n\r\n\r\n10\r\n\r\n\r\nShow code\r\n\r\nplot(churn_GBM1)\r\n\r\n\r\n\r\nShow code\r\n\r\n# test4\r\nchurn_GBM_pred1 <- predict(churn_GBM1, test, type = \"prob\")\r\nchurn_GBM_test_pred1 <- cbind(churn_GBM_pred1, test)\r\nchurn_GBM_test_pred1 <- churn_GBM_test_pred1 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_GBM_test_pred1$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             446             2592 \r\n\r\nShow code\r\n\r\n# result4\r\nchurn_matrix4 <- confusionMatrix(factor(churn_GBM_test_pred1$prediction), \r\n                                 factor(churn_GBM_test_pred1$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix4\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2529               63\r\n  AttritedCustomer               21              425\r\n                                          \r\n               Accuracy : 0.9724          \r\n                 95% CI : (0.9659, 0.9779)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8938          \r\n                                          \r\n Mcnemar's Test P-Value : 7.696e-06       \r\n                                          \r\n            Sensitivity : 0.8709          \r\n            Specificity : 0.9918          \r\n         Pos Pred Value : 0.9529          \r\n         Neg Pred Value : 0.9757          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1399          \r\n   Detection Prevalence : 0.1468          \r\n      Balanced Accuracy : 0.9313          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix4$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"pink\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Gradient Boosting Tree Confusion Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\nShow code\r\n\r\n# feature importance\r\n# summary(churn_GBM)\r\nvar_imp4 <- varImp(churn_GBM1, n.trees = 500)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp4))\r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n100.00000\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n86.21584\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n42.17720\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n34.47348\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n24.89156\r\n\r\n\r\nTotal_Revolving_Bal\r\n\r\n\r\n17.50240\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp4, aes(x = reorder(rownames(var_imp4), Overall), y = Overall)) +\r\n  geom_point(color = \"violet\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp4), xend = rownames(var_imp4), \r\n                   y = 0, yend = Overall), color = \"skyblue\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +  \r\n  coord_flip()\r\n\r\n\r\n\r\n\r\nvi. Gradient Boosting Tree Train NA✨\r\n\r\nOriginal data set with Training Set Missing Value Replaced and only replaced missing values in the training set\r\n\r\nThe model has 0.9691 of accuracy and 0.8805 in kappa, and recall is 0.8545\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex2 <- createDataPartition(BankChurners1$Attrition_Flag, \r\n                              p = .7, list = FALSE, times = 1)\r\n train2 <- BankChurners1[index,]\r\n test2 <- BankChurners1[-index,]\r\n table(is.na(train2))\r\n\r\n\r\n\r\n FALSE   TRUE \r\n134991   6789 \r\n\r\nShow code\r\n\r\n# replace missing values in the training set\r\ntrain2 <- VIM::kNN(train2, \r\n               variable = c(\"Dependent_count\", \"Education_Level\", \r\n                           \"Marital_Status\", \"Income_Level\", \r\n                           \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\",\r\n                           \"Total_Revolving_Bal\", \"Total_Amt_Chng_Q4_Q1\",\r\n                           \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\"),\r\n              k = 10)\r\n# summary(train2)\r\ntrain2 <- train2[,-c(21:30)]\r\ntable(is.na(train2))\r\n\r\n\r\n\r\n FALSE \r\n141780 \r\n\r\nShow code\r\n\r\n# train5\r\nchurn_GBM2 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train2,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"gbm\",\r\n  tuneLength = 10,\r\n  verbose = FALSE\r\n)\r\n# churn_GBM2\r\nkable(churn_GBM2$bestTune)\r\n\r\n\r\n\r\n\r\n\r\nn.trees\r\n\r\n\r\ninteraction.depth\r\n\r\n\r\nshrinkage\r\n\r\n\r\nn.minobsinnode\r\n\r\n\r\n85\r\n\r\n\r\n250\r\n\r\n\r\n9\r\n\r\n\r\n0.1\r\n\r\n\r\n10\r\n\r\n\r\nShow code\r\n\r\nplot(churn_GBM2)\r\n\r\n\r\n\r\nShow code\r\n\r\n# test5\r\nchurn_GBM_pred2 <- predict(churn_GBM2, test, type = \"prob\")\r\nchurn_GBM_test_pred2 <- cbind(churn_GBM_pred2, test2)\r\nchurn_GBM_test_pred2 <- churn_GBM_test_pred2 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_GBM_test_pred2$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             450             2588 \r\n\r\nShow code\r\n\r\n# result5\r\nchurn_matrix5 <- confusionMatrix(factor(churn_GBM_test_pred2$prediction), \r\n                                 factor(churn_GBM_test_pred2$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix5\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2526               62\r\n  AttritedCustomer               24              426\r\n                                          \r\n               Accuracy : 0.9717          \r\n                 95% CI : (0.9652, 0.9773)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8916          \r\n                                          \r\n Mcnemar's Test P-Value : 6.613e-05       \r\n                                          \r\n            Sensitivity : 0.8730          \r\n            Specificity : 0.9906          \r\n         Pos Pred Value : 0.9467          \r\n         Neg Pred Value : 0.9760          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1402          \r\n   Detection Prevalence : 0.1481          \r\n      Balanced Accuracy : 0.9318          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix5$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"lavender\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Gradient Boosting Tree Confusion Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\nvii. Gradient Boosting Tree Total NA & SMOTE\r\n\r\nOriginal data set with Total Missing Value Replaced and Resampling in the Training Set\r\n\r\nThe model has 0.9635 of accuracy and 0.8668 in kappa, which is similar to the previous result. The recall is 0.9078 🎉 (Mcnemar’s Test P-Value : 0.02545 🅿)\r\n\r\n\r\nShow code\r\n\r\n# data split\r\nindex <- createDataPartition(BankChurners2$Attrition_Flag, \r\n                             p = .7, list = FALSE, times = 1)\r\ntrain <- BankChurners2[index,]\r\ntest <- BankChurners2[-index,]\r\n\r\n# train6\r\nchurn_GBM3 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE,\r\n                           sampling = \"smote\"),\r\n  method = \"gbm\",\r\n  tuneLength = 10,\r\n  verbose = FALSE\r\n)\r\n# kable(churn_GBM3$bestTune)\r\n# plot(churn_GBM3)\r\n\r\n# test6\r\nchurn_GBM_pred3 <- predict(churn_GBM3, test, type = \"prob\")\r\nchurn_GBM_test_pred3 <- cbind(churn_GBM_pred3, test)\r\nchurn_GBM_test_pred3 <- churn_GBM_test_pred3 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_GBM_test_pred3$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             529             2509 \r\n\r\nShow code\r\n\r\n# result6\r\nchurn_matrix6 <- confusionMatrix(factor(churn_GBM_test_pred3$prediction), \r\n                                 factor(churn_GBM_test_pred3$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix6\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2472               37\r\n  AttritedCustomer               78              451\r\n                                          \r\n               Accuracy : 0.9621          \r\n                 95% CI : (0.9547, 0.9686)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8642          \r\n                                          \r\n Mcnemar's Test P-Value : 0.0001915       \r\n                                          \r\n            Sensitivity : 0.9242          \r\n            Specificity : 0.9694          \r\n         Pos Pred Value : 0.8526          \r\n         Neg Pred Value : 0.9853          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1485          \r\n   Detection Prevalence : 0.1741          \r\n      Balanced Accuracy : 0.9468          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix6$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"firebrick\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Gradient Boosting Tree & SMOTE Confusion Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\nShow code\r\n\r\n# feature importance\r\n# summary(churn_GBM)\r\nvar_imp5 <- varImp(churn_GBM3, n.trees = 500)$importance %>% \r\n  arrange(desc(Overall))\r\nkable(head(var_imp5))\r\n\r\n\r\n\r\n\r\n\r\nOverall\r\n\r\n\r\nTotal_Trans_Ct\r\n\r\n\r\n100.000000\r\n\r\n\r\nTotal_Trans_Amt\r\n\r\n\r\n30.220501\r\n\r\n\r\nTotal_Ct_Chng_Q4_Q1\r\n\r\n\r\n22.463371\r\n\r\n\r\nTotal_Relationship_Count\r\n\r\n\r\n16.367709\r\n\r\n\r\nMonths_Inactive_12_mon\r\n\r\n\r\n15.729941\r\n\r\n\r\nTotal_Amt_Chng_Q4_Q1\r\n\r\n\r\n6.665217\r\n\r\n\r\nShow code\r\n\r\nggplot(var_imp4, aes(x = reorder(rownames(var_imp5), Overall), y = Overall)) +\r\n  geom_point(color = \"powderblue\", size = 6, alpha = 1) +\r\n  geom_segment(aes(x = rownames(var_imp5), xend = rownames(var_imp5), \r\n                   y = 0, yend = Overall), color = \"plum1\") +\r\n  xlab(\"Variable\") +\r\n  ylab(\"Overall Importance\") +\r\n  theme_light() +  \r\n  coord_flip()\r\n\r\n\r\n\r\n\r\nviii. 🌜Neural Network Total NA🕊️\r\n\r\nOriginal data set with Total Missing Value Replaced\r\n\r\nThe model has 0.9351 of accuracy and 0.7446 in kappa, and recall is 0.7277😕. The ROC curve looks great🏄 ROC result description: _____.\r\n\r\n\r\nShow code\r\n\r\n# train7\r\nchurn_NNET <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProb =TRUE),\r\n  method = \"nnet\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 5,\r\n  trace= FALSE\r\n)\r\nplot(churn_NNET)\r\n\r\n\r\n\r\nShow code\r\n\r\n# test7\r\nchurn_NNET_pred <- predict(churn_NNET, test, type = \"prob\")\r\nchurn_NNET_test_pred <- cbind(churn_NNET_pred, test)\r\nchurn_NNET_test_pred <- churn_NNET_test_pred %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_NNET_test_pred$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             430             2608 \r\n\r\nShow code\r\n\r\nroc_NNET <- pROC::roc(factor(churn_NNET_test_pred$Attrition_Flag), \r\n                      churn_NNET_test_pred$ExistingCustomer)\r\nplot(roc_NNET)\r\n\r\n\r\n\r\nShow code\r\n\r\n# result7\r\nchurn_matrix7 <- confusionMatrix(factor(churn_NNET_test_pred$prediction), \r\n                                 factor(churn_NNET_test_pred$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix7\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2470              138\r\n  AttritedCustomer               80              350\r\n                                          \r\n               Accuracy : 0.9282          \r\n                 95% CI : (0.9185, 0.9372)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.7205          \r\n                                          \r\n Mcnemar's Test P-Value : 0.0001131       \r\n                                          \r\n            Sensitivity : 0.7172          \r\n            Specificity : 0.9686          \r\n         Pos Pred Value : 0.8140          \r\n         Neg Pred Value : 0.9471          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1152          \r\n   Detection Prevalence : 0.1415          \r\n      Balanced Accuracy : 0.8429          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix7$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"plum1\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Neural Network Confusion Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\nix. Neural Network Total NA & SMOTE\r\n\r\nOriginal data set with total missing value replaced & SMOTE resampling\r\n\r\nThe model has _____ of accuracy and _____ in kappa, which is ______ to the previous model. The recall is _____, _____ compared to the prior model.\r\nROC result description: _____.\r\n\r\n\r\nShow code\r\n\r\n# train8\r\nchurn_NNET2 <- train(\r\n  form = factor(Attrition_Flag) ~.,\r\n  data = train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProb = TRUE,\r\n                           sampling = \"smote\"),\r\n  method = \"nnet\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 5,\r\n  trace= FALSE\r\n)\r\nplot(churn_NNET2)\r\n\r\n\r\n\r\nShow code\r\n\r\n# test8\r\nchurn_NNET_pred2 <- predict(churn_NNET2, test, type = \"prob\")\r\nchurn_NNET_test_pred2 <- cbind(churn_NNET_pred2, test)\r\nchurn_NNET_test_pred2 <- churn_NNET_test_pred2 %>% \r\n  mutate(prediction = if_else(AttritedCustomer > ExistingCustomer, \r\n                              \"AttritedCustomer\", \"ExistingCustomer\"))\r\ntable(churn_NNET_test_pred2$prediction)\r\n\r\n\r\n\r\nAttritedCustomer ExistingCustomer \r\n             643             2395 \r\n\r\nShow code\r\n\r\nroc_NNET <- pROC::roc(factor(churn_NNET_test_pred2$Attrition_Flag), \r\n                      churn_NNET_test_pred2$ExistingCustomer)\r\nplot(roc_NNET2)\r\n\r\n\r\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'roc_NNET2' not found\r\n\r\nShow code\r\n\r\n# result8\r\nchurn_matrix8 <- confusionMatrix(factor(churn_NNET_test_pred2$prediction), \r\n                                 factor(churn_NNET_test_pred2$Attrition_Flag), \r\n                                 positive = \"AttritedCustomer\")\r\nchurn_matrix8\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                  Reference\r\nPrediction         ExistingCustomer AttritedCustomer\r\n  ExistingCustomer             2325               70\r\n  AttritedCustomer              225              418\r\n                                          \r\n               Accuracy : 0.9029          \r\n                 95% CI : (0.8918, 0.9132)\r\n    No Information Rate : 0.8394          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.6809          \r\n                                          \r\n Mcnemar's Test P-Value : < 2.2e-16       \r\n                                          \r\n            Sensitivity : 0.8566          \r\n            Specificity : 0.9118          \r\n         Pos Pred Value : 0.6501          \r\n         Neg Pred Value : 0.9708          \r\n             Prevalence : 0.1606          \r\n         Detection Rate : 0.1376          \r\n   Detection Prevalence : 0.2117          \r\n      Balanced Accuracy : 0.8842          \r\n                                          \r\n       'Positive' Class : AttritedCustomer\r\n                                          \r\n\r\nShow code\r\n\r\nggplot(as.data.frame(churn_matrix8$table)) +\r\n  geom_raster(aes(x = Reference, y = Prediction, fill = Freq)) +\r\n  geom_text(aes(x = Reference, y = Prediction, label = Freq)) +\r\n  scale_fill_gradient2(low = \"darkred\", high = \"maroon\",\r\n                       na.value = \"grey\", name = \"Freq\") +\r\n  scale_x_discrete(name = \"Actual Class\") +\r\n  scale_y_discrete(name = \"Predicted Class\") +\r\n  ggtitle(\"Neural Network Confusion Matrix\") +\r\n  theme(plot.title = element_text(hjust = .5, size = 10, face = \"bold\"))\r\n\r\n\r\n\r\n\r\nVI. Result\r\nOverall, 🌳random forest model has the best performance🏆 compared to gradient boosting tree and neural network🌲, especially after replacing total missing values and using SMOTE to fix 🔧 the imbalanced data set issue. (iv.RF TOTAL NA & SMOTE)\r\n\r\n\r\nShow code\r\n\r\ncomparison <- matrix(c(0.9661, 0.8683, 0.8381, 0.9585, 0.8409, 0.8308, 0.9575, 0.8341, \r\n                       0.8062, 0.9549, 0.8423, 0.9344, 0.9681, 0.8781, 0.8648, 0.9691,  \r\n                       0.8805, 0.8545, 0.9635, 0.8668, 0.9078, 0.9351, 0.7446, 0.7277,\r\n                       0.0000, 0.0000, 0.0000),\r\n                     ncol = 3, byrow = TRUE)\r\ncolnames(comparison) <- c(\"Accuracy\", \"Kappa\", \"Recall\")\r\nrownames(comparison) <- c(\"i.RF TOTAL NA\", \"ii.RF TOTAL NA & VAR\", \"iii.RF TRAIN NA\", \r\n                          \"iv.RF TOTAL NA & SMOTE\", \"v.GBT TOTAL NA\", \"vi.GBT TRAIN NA\", \r\n                          \"vii.GBT TOTAL NA & SMOTE\", \"viii.NNET TOTAL NA\", \"ix.NNET TOTAL NA & SMOTE\")\r\ncomparison <- as.data.frame.matrix(comparison)\r\nkable(comparison) %>% \r\n  row_spec(4, color = \"white\", background = \"#bdaeea\")\r\n\r\n\r\n\r\n\r\n\r\nAccuracy\r\n\r\n\r\nKappa\r\n\r\n\r\nRecall\r\n\r\n\r\ni.RF TOTAL NA\r\n\r\n\r\n0.9661\r\n\r\n\r\n0.8683\r\n\r\n\r\n0.8381\r\n\r\n\r\nii.RF TOTAL NA & VAR\r\n\r\n\r\n0.9585\r\n\r\n\r\n0.8409\r\n\r\n\r\n0.8308\r\n\r\n\r\niii.RF TRAIN NA\r\n\r\n\r\n0.9575\r\n\r\n\r\n0.8341\r\n\r\n\r\n0.8062\r\n\r\n\r\niv.RF TOTAL NA & SMOTE\r\n\r\n\r\n0.9549\r\n\r\n\r\n0.8423\r\n\r\n\r\n0.9344\r\n\r\n\r\nv.GBT TOTAL NA\r\n\r\n\r\n0.9681\r\n\r\n\r\n0.8781\r\n\r\n\r\n0.8648\r\n\r\n\r\nvi.GBT TRAIN NA\r\n\r\n\r\n0.9691\r\n\r\n\r\n0.8805\r\n\r\n\r\n0.8545\r\n\r\n\r\nvii.GBT TOTAL NA & SMOTE\r\n\r\n\r\n0.9635\r\n\r\n\r\n0.8668\r\n\r\n\r\n0.9078\r\n\r\n\r\nviii.NNET TOTAL NA\r\n\r\n\r\n0.9351\r\n\r\n\r\n0.7446\r\n\r\n\r\n0.7277\r\n\r\n\r\nix.NNET TOTAL NA & SMOTE\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\nThe original model from Kaggle has 0.62 for recall, so 🤠my models did improve the performance of predicting churned customers🥳. They can help companies to identify potential customer churn with higher success rate. The neural network model _____. Based on the variable importance rates, customers’ transaction numbers and amounts, changes in transaction amount, and total product held by customers are the most important⭐ predicting variables in those models. The demographic factors are not important in those models though.\r\nLimitations:\r\n\r\nhttps://www.kaggle.com/sakshigoyal7/credit-card-customers↩︎\r\nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222916↩︎\r\nhttps://en.wikipedia.org/wiki/Gradient_boosting↩︎\r\n",
      "last_modified": "2022-01-18T15:06:17-06:00"
    },
    {
      "path": "index.html",
      "title": "Siwei Jiang",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          \r\n          \r\n          Siwei Jiang\r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          \r\n          Resume\r\n          \r\n          \r\n          Project\r\n           \r\n          ▾\r\n          \r\n          \r\n          Rsquared\r\n          Machine Learning\r\n          Customer Churn Prediction\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            Siwei Jiang\r\n          \r\n          \r\n            \r\n              Hello, I am a master student studying accounting in Mississippi State University. Hope one day I can be a 🧭mountaineer🧗🚵️🌋🌄️🗻🚞 “Because IT’s there” \r\n            \r\n            \r\n              Hello, I am a master student studying accounting in Mississippi State University. Hope one day I can be a 🧭mountaineer🧗🚵️🌋🌄️🗻🚞 “Because IT’s there” \r\n            \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                      Github\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Blog\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                    Github\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Email\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Blog\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2022-01-18T15:06:18-06:00"
    },
    {
      "path": "ml.html",
      "title": "Machine Learning",
      "description": "[Support Vector Machines](https://professor-hunt.github.io/ACC8143/Support_Vector_Machine.html){target=\"_blank\"} \n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nI. The Model\r\nII. The Process and Results\r\nIII. Application\r\nIV. Code\r\ni. Data Split 75:25\r\nii. Data Split 50:50\r\niii. Kernel: svmPoly\r\n\r\n\r\nI. The Model\r\n👩‍💻A Support Vector Machine (SVM) model is a supervised👀 machine learning model used for classification. It is simple but very useful. It uses a tool🔨 called hyperplane to separate data into different groups. It has different methods for both linear and non-linear data. And the methods that are used here are svmLinear and svmPloy.\r\nII. The Process and Results\r\nSince SVM is a supervised model, the first step is to split the dataset into training and testing sets and assume the dataset is clean♻️. After the dataset split, we run🏃 the SVM in the training set and use the trained data to predict the testing set. Finally, we use a 📐📏confusion matrix to show how well is our prediction in terms of accuracy, recall, Specificity, etc.\r\nWe are 🔭interested in the effect of data split ratios on the model performance, so we compare two new ratios, 75:25 and 50:50 with the original ratio of 60:40 conducted by Dr.Hunt. We also implement both linear and poly methods on the dataset to see the difference in their performance.\r\nThe result for both splits and poly method are better📈 than the original model performance, which means that data split does have an impact on the model fitness. 🎊Because we know that two classes of variables have some overlaps, so it is expected that poly will be a better fit for the dataset. However, we did not test statistical significance for those changes🙊.\r\n\r\n\r\nShow code\r\n\r\ncomparison <- matrix(c(0.9333, 0.9000, 0.7938, 0.8500, 0.9444, 0.9167, 0.8333, 1.0000,\r\n                       0.9467, 0.9200, 0.9600, 0.8800, 0.9667, 0.9500, 0.9000, 1.0000),\r\n                    ncol = 4, byrow = TRUE)\r\ncolnames(comparison) <- c(\"Accuracy\", \"Kappa\", \"Recall-Versi\", \"Recall-Virgi\")\r\nrownames(comparison) <- c(\"Linear 60:40\", \"Linear 75:25\", \"Linear 50:50\", \"NonLin 60:40\")\r\ncomparison <- as.data.frame.matrix(comparison)\r\nkable(comparison)\r\n\r\n\r\n\r\n\r\n\r\nAccuracy\r\n\r\n\r\nKappa\r\n\r\n\r\nRecall-Versi\r\n\r\n\r\nRecall-Virgi\r\n\r\n\r\nLinear 60:40\r\n\r\n\r\n0.9333\r\n\r\n\r\n0.9000\r\n\r\n\r\n0.7938\r\n\r\n\r\n0.85\r\n\r\n\r\nLinear 75:25\r\n\r\n\r\n0.9444\r\n\r\n\r\n0.9167\r\n\r\n\r\n0.8333\r\n\r\n\r\n1.00\r\n\r\n\r\nLinear 50:50\r\n\r\n\r\n0.9467\r\n\r\n\r\n0.9200\r\n\r\n\r\n0.9600\r\n\r\n\r\n0.88\r\n\r\n\r\nNonLin 60:40\r\n\r\n\r\n0.9667\r\n\r\n\r\n0.9500\r\n\r\n\r\n0.9000\r\n\r\n\r\n1.00\r\n\r\n\r\nIII. Application\r\nThe SVM model can be used for identifying abnormalities such as fraudulent transactions, material misstatements, bankruptcies, abnormal reserves, etc. Auditors can utilize this machine learning model with other algorithms as well as financial ratios to improve their accuracy and efficiency.\r\nIV. Code\r\ni. Data Split 75:25\r\nAccuracy and Kappa both increased a little✨ bit\r\nData Preparation\r\n\r\n\r\nShow code\r\n\r\n# data split\r\niris1 <- iris\r\ntrain_index <- createDataPartition(iris1$Species, p = .75, list = FALSE, times = 1)\r\n\r\niris_train <- iris1[train_index,]\r\niris_test <- iris1[-train_index,]\r\n\r\n\r\n\r\nModel\r\n\r\n\r\nShow code\r\n\r\n# train\r\niris_svm_train <- train(\r\n  form = factor(Species) ~.,\r\n  data = iris_train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"svmLinear\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10\r\n)\r\n# iris_svm_train\r\nsummary(iris_svm_train)\r\n\r\n\r\nLength  Class   Mode \r\n     1   ksvm     S4 \r\n\r\nShow code\r\n\r\n# predict\r\niris_svm_predict <- predict(iris_svm_train, iris_test, type = \"prob\")\r\n\r\niris_svm_predict <- cbind(iris_svm_predict, iris_test)\r\niris_svm_predict <- iris_svm_predict %>% \r\n  mutate(prediction = if_else(setosa > versicolor & setosa > virginica, \"setosa\",\r\n                              if_else(versicolor > setosa & versicolor > virginica, \"versicolor\",\r\n                                      if_else(virginica > setosa & virginica > versicolor, \"virginica\", \"PROBLEM\"))))\r\n# table(iris_svm_predict$prediction)\r\nconfusionMatrix(factor(iris_svm_predict$prediction), factor(iris_svm_predict$Species))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         12          0         0\r\n  versicolor      0         10         0\r\n  virginica       0          2        12\r\n\r\nOverall Statistics\r\n                                          \r\n               Accuracy : 0.9444          \r\n                 95% CI : (0.8134, 0.9932)\r\n    No Information Rate : 0.3333          \r\n    P-Value [Acc > NIR] : 1.728e-14       \r\n                                          \r\n                  Kappa : 0.9167          \r\n                                          \r\n Mcnemar's Test P-Value : NA              \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            0.8333           1.0000\r\nSpecificity                 1.0000            1.0000           0.9167\r\nPos Pred Value              1.0000            1.0000           0.8571\r\nNeg Pred Value              1.0000            0.9231           1.0000\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.2778           0.3333\r\nDetection Prevalence        0.3333            0.2778           0.3889\r\nBalanced Accuracy           1.0000            0.9167           0.9583\r\n\r\nPlot SVM\r\n\r\n\r\nShow code\r\n\r\nsv1 <- iris_train[iris_svm_train$finalModel@SVindex,]\r\n\r\nggplot(data = iris_test, mapping = aes(x = Sepal.Width, y= Petal.Width, color = Species)) +\r\n  geom_point(alpha = .5) +\r\n  geom_point(data = iris_svm_predict, mapping = aes(x = Sepal.Width, y = Petal.Width, color = prediction), \r\n             shape = 6, size = 3) +\r\n  geom_point(data = sv1, mapping = aes(x = Sepal.Width, y = Petal.Width), shape = 4, size = 4) +\r\n  theme(legend.title = element_blank()) +\r\n  ggtitle(\"Support Vector Machine\")\r\n\r\n\r\n\r\n\r\nii. Data Split 50:50\r\nAccuracy and Kappa both increased a little. Versicolor’s recall increased a lot👏\r\nModel\r\n\r\n\r\nShow code\r\n\r\n# data split\r\ntrain_index <- createDataPartition(iris1$Species, p = .5, list = FALSE, times = 1)\r\n\r\niris_train <- iris1[train_index,]\r\niris_test <- iris1[-train_index,]\r\n\r\n# train\r\niris_svm_train <- train(\r\n  form = factor(Species) ~.,\r\n  data = iris_train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"svmLinear\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10\r\n)\r\n# iris_svm_train\r\nsummary(iris_svm_train)\r\n\r\n\r\nLength  Class   Mode \r\n     1   ksvm     S4 \r\n\r\nShow code\r\n\r\n# predict\r\niris_svm_predict <- predict(iris_svm_train, iris_test, type = \"prob\")\r\n\r\niris_svm_predict <- cbind(iris_svm_predict, iris_test)\r\niris_svm_predict <- iris_svm_predict %>% \r\n  mutate(prediction = if_else(setosa > versicolor & setosa > virginica, \"setosa\",\r\n                              if_else(versicolor > setosa & versicolor > virginica, \"versicolor\",\r\n                                      if_else(virginica > setosa & virginica > versicolor, \"virginica\", \"PROBLEM\"))))\r\n# table(iris_svm_predict$prediction)\r\nconfusionMatrix(factor(iris_svm_predict$prediction), factor(iris_test$Species))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         25          0         0\r\n  versicolor      0         24         3\r\n  virginica       0          1        22\r\n\r\nOverall Statistics\r\n                                         \r\n               Accuracy : 0.9467         \r\n                 95% CI : (0.869, 0.9853)\r\n    No Information Rate : 0.3333         \r\n    P-Value [Acc > NIR] : < 2.2e-16      \r\n                                         \r\n                  Kappa : 0.92           \r\n                                         \r\n Mcnemar's Test P-Value : NA             \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            0.9600           0.8800\r\nSpecificity                 1.0000            0.9400           0.9800\r\nPos Pred Value              1.0000            0.8889           0.9565\r\nNeg Pred Value              1.0000            0.9792           0.9423\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.3200           0.2933\r\nDetection Prevalence        0.3333            0.3600           0.3067\r\nBalanced Accuracy           1.0000            0.9500           0.9300\r\n\r\niii. Kernel: svmPoly\r\nHas the 🏆best overall and individual class performance\r\nModel\r\n\r\n\r\nShow code\r\n\r\ntrain_index <- createDataPartition(iris1$Species, p = .6, list = FALSE, times = 1)\r\n\r\niris_train <- iris1[train_index,]\r\niris_test <- iris1[-train_index,]\r\n\r\n# train\r\niris_svm_train <- train(\r\n  form = factor(Species) ~.,\r\n  data = iris_train,\r\n  trControl = trainControl(method = \"cv\",\r\n                           number = 10,\r\n                           classProbs = TRUE),\r\n  method = \"svmPoly\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10\r\n)\r\nsummary(iris_svm_train)\r\n\r\n\r\nLength  Class   Mode \r\n     1   ksvm     S4 \r\n\r\nShow code\r\n\r\n# predict\r\niris_svm_predict <- predict(iris_svm_train, iris_test, type = \"prob\")\r\niris_svm_predict <- cbind(iris_svm_predict, iris_test)\r\n\r\niris_svm_predict <- iris_svm_predict %>% \r\n  mutate(prediction = if_else(setosa > versicolor & setosa > virginica, \"setosa\",\r\n                              if_else(versicolor >setosa & versicolor > virginica, \"versicolor\",\r\n                                      if_else(virginica > setosa & virginica > versicolor, \"virginica\", \"PROBLEM\"))))\r\n# table(iris_svm_predict$prediction)\r\nconfusionMatrix(factor(iris_svm_predict$prediction), factor(iris_test$Species))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         20          0         0\r\n  versicolor      0         18         0\r\n  virginica       0          2        20\r\n\r\nOverall Statistics\r\n                                          \r\n               Accuracy : 0.9667          \r\n                 95% CI : (0.8847, 0.9959)\r\n    No Information Rate : 0.3333          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.95            \r\n                                          \r\n Mcnemar's Test P-Value : NA              \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            0.9000           1.0000\r\nSpecificity                 1.0000            1.0000           0.9500\r\nPos Pred Value              1.0000            1.0000           0.9091\r\nNeg Pred Value              1.0000            0.9524           1.0000\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.3000           0.3333\r\nDetection Prevalence        0.3333            0.3000           0.3667\r\nBalanced Accuracy           1.0000            0.9500           0.9750\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-01-18T15:06:22-06:00"
    },
    {
      "path": "resume.html",
      "title": "Résumé",
      "author": [],
      "contents": "\r\n\r\n\r\na {n  \r\n  text-decoration: none; \r\n  color: rgba(121, 205, 205);\r\n}\r\na:hover {\r\n  color: rgba(255, 182, 255, 0.8);\r\n}\r\nul {\r\n  list-style: none; /* Remove list bullets bcz don't know how to change color */\r\n  padding: 0;\r\n  margin: 0;\r\n}\r\nli::before {\r\n  content: \"•\"; \r\n  color: \"#5A59A3\";\r\n}\r\nh1 {\r\n  font-family: candara; /* title */\r\n  font-style: italic;\r\n}\r\nh2 {\r\n  font-family: candara;\r\n  font-style: italic;\r\n  color: rgba(134, 35, 141, 0.72);\r\n}\r\np code,\r\nli code {\r\n    line-height: 2.0; \r\n    white-space: nowrap;\r\n}\r\nbody {\r\n    width: 100vw;\r\n    height: 100vh;\r\n    margin: 0;\r\n    background: linear-gradient(\r\n        130deg, \r\n        #5A59A3, \r\n        #C66060\r\n    ) no-repeat  fixed;\r\n}\r\n\r\nEducation\r\nMaster in Taxation: Adkerson School of Accountancy May 2022\r\nBachelor of Business in Accounting: Adkerson School of Accountancy May 2020\r\nMinor in Business Analytics\r\nMississippi State University, Mississippi State, MS\r\nWorking Experience\r\n  Private Accountant for a Fire Protection Service CompanyFall 2014 – Fall 2015\r\n  Hunan, China\r\n              Journal entries and general ledger preparation\r\n              Bank statements and reconciliation\r\n              Examining expenses submitted by the construction manager\r\n              Taxation preparation during tax season\r\nCourse Group Projects\r\n  PowerPoint and social platforms: Marketing strategy plans for a drone startup\r\n  Excel and Word: Prepared consolidated financial reports for company acquisition\r\n  R: Bankruptcy analysis. Methods: holdout validation in discriminant analysis and logistic         regression analysis, and cross-validation in decision tree analysis.                             Customer Churn prediction. Methods: cross-validation in random forest and gradient         boosting.\r\nComputer Skills\r\n  Advanced in Microsoft Office including Excel, Word, and PowerPoint\r\n  Developing knowledge in Access, R, SAS, and Tableau\r\nVolunteer Work\r\n  West Point Clay County Animal Shelter\r\n  MSU Community Garden\r\n  Starkville Community Farmers Market\r\n  The Salvation Army\r\n\r\n\r\n\r\n",
      "last_modified": "2022-01-18T15:06:24-06:00"
    },
    {
      "path": "rsquared.html",
      "title": "R-squared",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nI. Why\r\nII. Time to Blow RSquared Up 💥\r\n1. \\(R^2\\) does not measure goodness of fit.\r\n2. \\(R^2\\) can be arbitrarily close to 1 when the model is totally wrong.\r\n3. \\(R^2\\) says nothing about prediction error\r\n4. \\(R^2\\) can easily go down when the model assumptions are better fulfilled.\r\n5. \\(R^2\\) does not measure how one variable explains another\r\n\r\nIII. So\r\n\r\nI. Why\r\n\r\nIt is easy to manipulate underlying data and make legitimate statements without giving a full context. For analyses/claims that use R-squared, we should be cautious and not interpret it alone as a measure of how well a model fits the data.\r\n\r\nII. Time to Blow RSquared Up1 💥\r\nR-squared is a statistic that often accompanies regression output. It ranges in value from 0 to 1 and is usually interpreted as summarizing the percent of variation in the response that the regression model explains. So an R-squared of 0.65 might mean that the model explains about 65% of the variation in our dependent variable. Given this logic, we prefer our regression models have a high R-squared.\r\nIn R, we typically get R-squared by calling the summary function on a model object. Here’s a quick example using simulated data:\r\n\r\n\r\n# independent variable\r\nx <- 1:20 \r\n# for reproducibility\r\nset.seed(1) \r\n# dependent variable; function of x with random error\r\ny <- 2 + 0.5*x + rnorm(20,0,3) \r\n# simple linear regression\r\nmod <- lm(y~x)\r\n# request just the r-squared value\r\nsummary(mod)$r.squared          \r\n\r\n\r\n[1] 0.6026682\r\n\r\nOne way to express R-squared is as the sum of squared fitted-value deviations divided by the sum of squared original-value deviations:\r\n\\[\r\nR^{2} =  \\frac{\\sum (\\hat{y} – \\bar{\\hat{y}})^{2}}{\\sum (y – \\bar{y})^{2}}\r\n\\]\r\nWe can calculate it directly using our model object like so:\r\n\r\n\r\n# extract fitted (or predicted) values from model\r\nf <- mod$fitted.values\r\n# sum of squared fitted-value deviations\r\nmss <- sum((f - mean(f))^2)\r\n# sum of squared original-value deviations\r\ntss <- sum((y - mean(y))^2)\r\n# r-squared\r\nmss/tss                      \r\n\r\n\r\n[1] 0.6026682\r\n\r\n1. \\(R^2\\) does not measure goodness of fit.\r\nIt can be arbitrarily low when the model is completely correct.* By making\\(σ^2\\) large, we drive R-squared towards 0, even when every assumption of the simple linear regression model is correct in every particular.\r\nWhat is \\(σ^2\\)? When we perform linear regression, we assume our model almost predicts our dependent variable. The difference between “almost” and “exact” is assumed to be a draw from a Normal distribution with mean 0 and some variance we call \\(σ^2\\).\r\nThis statement is easy enough to demonstrate. The way we do it here is to create a function that (1) generates data meeting the assumptions of simple linear regression (independent observations, normally distributed errors with constant variance), (2) fits a simple linear model to the data, and (3) reports the R-squared. Notice the only parameter for sake of simplicity is sigma. We then “apply” this function to a series of increasing \\(σ\\) values and plot the results.\r\n\r\n\r\nr2.0 <- function(sig){\r\n  # our predictor\r\n  x <- seq(1,10,length.out = 100)   \r\n  # our response; a function of x plus some random noise\r\n  y <- 2 + 1.2*x + rnorm(100,0,sd = sig) \r\n  # print the R-squared value\r\n  summary(lm(y ~ x))$r.squared          \r\n}\r\nsigmas <- seq(0.5,20,length.out = 20)\r\n # apply our function to a series of sigma values\r\nrout <- sapply(sigmas, r2.0)            \r\nplot(rout ~ sigmas, type=\"b\")\r\n\r\n\r\n\r\n\r\nR-squared tanks hard with increasing sigma, even though the model is completely correct in every respect.\r\n2. \\(R^2\\) can be arbitrarily close to 1 when the model is totally wrong.\r\nThe point being made is that R-squared does not measure goodness of fit.\r\n\r\n\r\nset.seed(1)\r\n# our predictor is data from an exponential distribution\r\nx <- rexp(50,rate=0.005)\r\n# non-linear data generation\r\ny <- (x-1)^2 * runif(50, min=0.8, max=1.2) \r\n# clearly non-linear\r\nplot(x,y)             \r\n\r\n\r\n\r\n\r\n\r\n\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.8485146\r\n\r\nIt’s very high at about 0.85, but the model is completely wrong. Using R-squared to justify the “goodness” of our model in this instance would be a mistake. Hopefully one would plot the data first and recognize that a simple linear regression in this case would be inappropriate.\r\n3. \\(R^2\\) says nothing about prediction error\r\nEven with* \\(σ^2\\) exactly the same, and no change in the coefficients. R-squared can be anywhere between 0 and 1 just by changing the range of X. We’re better off using Mean Square Error (MSE) as a measure of prediction error.\r\nMSE is basically the fitted y values minus the observed y values, squared, then summed, and then divided by the number of observations.\r\nLet’s demonstrate this statement by first generating data that meets all simple linear regression assumptions and then regressing y on x to assess both R-squared and MSE.\r\n\r\n\r\nx <- seq(1,10,length.out = 100)\r\nset.seed(1)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 0.9)\r\nmod1 <- lm(y ~ x)\r\nsummary(mod1)$r.squared\r\n\r\n\r\n[1] 0.9383379\r\n\r\n# Mean squared error\r\nsum((fitted(mod1) - y)^2)/100\r\n\r\n\r\n[1] 0.6468052\r\n\r\nNow repeat the above code, but this time with a different range of x. Leave everything else the same:\r\n\r\n\r\n # new range of x\r\nx <- seq(1,2,length.out = 100)      \r\nset.seed(1)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 0.9)\r\nmod1 <- lm(y ~ x)\r\nsummary(mod1)$r.squared\r\n\r\n\r\n[1] 0.1502448\r\n\r\n# Mean squared error\r\nsum((fitted(mod1) - y)^2)/100        \r\n\r\n\r\n[1] 0.6468052\r\n\r\nThe R-squared falls from 0.94 to 0.15 but the MSE remains the same. In other words the predictive ability is the same for both data sets, but the R-squared would lead you to believe the first example somehow had a model with more predictive power.\r\n4. \\(R^2\\) can easily go down when the model assumptions are better fulfilled.\r\nLet’s examine this by generating data that would benefit from transformation. Notice the R code below is very much like our previous efforts but now we exponentiate our y variable.\r\n\r\n\r\nx <- seq(1,2,length.out = 100)\r\nset.seed(1)\r\ny <- exp(-2 - 0.09*x + rnorm(100,0,sd = 2.5))\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.003281718\r\n\r\nplot(lm(y ~ x), which=3)\r\n\r\n\r\n\r\n\r\nR-squared is very low and our residuals vs. fitted plot reveals outliers and non-constant variance. A common fix for this is to log transform the data. Let’s try that and see what happens:\r\n\r\n\r\nplot(lm(log(y)~x),which = 3) \r\n\r\n\r\n\r\n\r\nThe diagnostic plot looks much better. Our assumption of constant variance appears to be met. But look at the R-squared:\r\n\r\n\r\nsummary(lm(log(y)~x))$r.squared \r\n\r\n\r\n[1] 0.0006921086\r\n\r\nIt’s even lower! This is an extreme case and it doesn’t always happen like this. In fact, a log transformation will usually produce an increase in R-squared. But as just demonstrated, assumptions that are better fulfilled don’t always lead to higher R-squared.\r\n5. \\(R^2\\) does not measure how one variable explains another\r\nIt is very common to say that R-squared is “the fraction of variance explained” by the regression. \\[Yet\\] if we regressed X on Y, we’d get exactly the same R-squared. This in itself should be enough to show that a high R-squared says nothing about explaining one variable by another.\r\nThis is the easiest statement to demonstrate:\r\n\r\n\r\nx <- seq(1,10,length.out = 100)\r\ny <- 2 + 1.2*x + rnorm(100,0,sd = 2)\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.737738\r\n\r\nsummary(lm(x ~ y))$r.squared\r\n\r\n\r\n[1] 0.737738\r\n\r\nDoes x explain y, or does y explain x? Are we saying “explain” to dance around the word “cause”? In a simple scenario with two variables such as this, R-squared is simply the square of the correlation between x and y:\r\n\r\n\r\nall.equal(cor(x,y)^2, summary(lm(x ~ y))$r.squared, summary(lm(y ~ x))$r.squared)\r\n\r\n\r\n[1] TRUE\r\n\r\nLet’s recap:\r\nR-squared does not measure goodness of fit.\r\nR-squared does not measure predictive error.\r\nR-squared does not necessarily increase when assumptions are better satisfied.\r\nR-squared does not measure how one variable explains another.\r\nIII. So\r\n\r\nAlthough different fields have different acceptable values for the R-squared, we could just use other measures for goodness of fit like MSE.\r\n\r\n\r\nhttps://data.library.virginia.edu/is-r-squared-useless/↩︎\r\n",
      "last_modified": "2022-01-18T15:06:31-06:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
